
======================DNS   bind,
www.isc.org

catching-nameserver,bind-utils软件包

./conifgure --sysconfdir=/etc   默认的是PREFIX/etc
make
make install

/etc/named.conf
opotions { directory "/var/named"; };  注意在{} 前有空格
catching-nameserver.rpm软件包,安装会产生一个named.conf文件

dig -t NS .  根服务器的主机
如果只有一个根主机 A 表示的 (address) 把它的地址放入resolv.conf中再次 dit -t NS .
dig -t NS .>/etc/named/named.ca　　//有了很多的根域服务器的地址
再换成本机IP来解析DNS
echo "nameserver 127.0.0.1">/etc/resolv.conf

rndc-confgen > /etc/rndc.conf
看提示把文件下半部分放在named.conf文件中

cat -n 显示行号

tail +13 /etc/rndc.conf >> /etc/named.conf  从第13行到尾

(tail -n +2 从第二行开始到尾,-2从倒数第二行开始到尾)
tail -10f console.log　看尾最后10行

删除注释
VI中 :.,$-1s/^#\ //　　　
.表示当前行，$表示最后一行,s/.../替换 (行首的#和空格转义)　/删除　　　
看/var/log/messages 日志文件

named来启动
ps -aux | grep named   :53 端口 (domain)


host www.google.cn来测试

rndc status 显示信息

host和dig是让nameserver来查找的 不会去找hosts文件中的


zone "." IN(可无)
{
type hint;
file "named.ca";
};


zone "localhost" IN
{
type master;
file "named.local";
};

/var/named/named.local文件

////@表示传过来的区名(即 zone 后的字符串)
////IN inernet类型
////SOA (start of authority)
////管理员 root 或者 root.localhost. (因为@有特意不能root@localhost)   注意尾部点表示全称
@ 1D IN SOA localhost. root.locahost. (  #1D １天
#这里的root.localhost.可以省为root ,"."表示完成，@表示传来的域名　"("前要有空格
#　Ｈ小时　Ｍ分钟　Ｗ周  D天
#;表示注注释
23232 ;serial  更新次数  
1H ;refresh
15M ;retry
1w  ;expire
1D 　;TTL  缓存时间
)


#A 表示地址　
#　　　@第一个字段为空表示于上一行相同
#NS　域名
#CNAME  表示别名

localhost.( 与上行同可省，或@ 域名)   IN    NS  locahost.(主机名,可用@)     #第一个localhost的域名服务器的第二loc
localhost.		IN    A   127.0.0.1                   #localhost对应上面第二个的IP


rndc reload重新加载named.conf文件
 
dig -t A localhost 信息要比host多一些,可存文件
(yum install bind-utils)
dig -t A localhost @<DNSIP>

就可以用host  localhost来解析了


hostname   FQDN
$origin chinaitlab.com  默认域的后缀
@ 1D IN SOA chainitlab.com. root (   #root.chainitlab.com.
	23232
	1H
	15M
	1W
	1D  )
      IN NS   ns      #ns.chinaitlab.com. 可以把NS 改为@,并改一下ns行的ns删 ,NS后只可是主机名,不可以是IP
      IN MX 10 mail   #mail.chinaitlab.com.  (Mail Exchange 一定要可以解析的,所以下面要有对应的)
ns    IN  A     10.0.0.254)
www   IN  A      10.0.0.454
mail  IN  A     10.0.0.254
new   IN  CNAME     www            #如www变了,new这个别名也变了




/etc/resolv.conf文件中的   search example.com 
表示   host www 时会www.example.com


127.0.0的反向区
zone "0.0.127.in-addr.arpa" {
	type master ;
	file "127.0.0.zone" ;
};



$TTL 1D ####$TTL 3h 缓存时间,表示该文件所有第 一行的第二列可以省1D
###@ 表示0.0.127.in-addr.arpa.    root.localhost.不能简写成root
@	IN	SOA  @	root.localhost. (121 1H 30M 1W 1D)  ##第二个@用正向,返向无所谓的
	IN	NS	localhost.
1	IN	PTR	localhost.   ## 1 = 1.0.0.127.in-addr.arpa. 


rndc reload
host 127.0.0.1 来测试
dig -x 127.0.0.1   或是 dig -t PTR(pointer) 1.0.0.127.in-addr.arpa


history看操作历史
子不知道父，在/etc/resolv.conf加　search  278.xxxxxx

zone "" {
type "slave";
file "chaineitlab";
masters { 10.0.0.1; } ;   #{}前后最好有空格
};

host -t SOA chinaitlab.com

named 是以named用户来运行的不可以写root 的文件/var/named/  (slave)
refresh 来决定 多长时间从主服务器上根据serial拿最新的数据,如主服务器不通retry的时间来重试,什么时候过期,最后一个是缓存

useradd -s /bin/false -d /dev/null named
mkdir /var/run/named 
chown named.named /var/run/named
named -u named    表示以指定的用户(named)运行  会写/var/run 进程信息,要建一目录

/etc/rc.loacal 开机启动运行


options {pid-file "/var/run/named/named.pid"}
###全局有效
options
{
	forwarders { 192.168.1.1; } ;#如果自己不能解析，发给ＩＰ来解析，如也不能解析，就给根来解析
	allow-transfer { 192.168.1.1; } ;#充许传输文件的ＩＰ(对slave)，可放在　zone "xx" 中
	allow-query { 10.0.0/24 } ;  充许查询的IP(解析) 
}

/var/named/chroot/
ls /var/named/chroot/var/named/
zone "xx.com" IN
{
	allow-update{none;}
}

nslookup  后输入 域名来解析 ，（resolv.conf）
canonical
[kE5nCnikEl]
adj.
规范的
VMWare的Team

/var/named/chroot/var目录要正确权限(755)，否则slave不能从master,更新服务
chmod 755 -R chroot

dig -t A  xxx.com @<DNS-IP>
dig -t A  nginx.default.svc.cluster.local @10.96.0.10 

======================DHCP======================
www.isc.org   
	DHCP 支持ipv4和ipv6
	Kea 支持DHCPv4 和 DHCPv6  为了替换 DHCP


man dhcpd.conf

示例：

ddns-update-style none;##必须要有，man dhcp.conf

subnet 10.0.0.0 netmask 255.255.255.0{
	option routers		10.0.0.254;   
	option  subnet-mask	255.255.255.0;
	option domain-name	"chainitlib.com";#windows ipconfig会显示DNS suffix，/etc/resolv.conf中有search chainitlib.com
	option domain-name-servers 10.0.0.254;   #DNS服务的IP多个 ,要分号，不在range范围中有
	range 10.0.0.128 10.0.0.253;             #分配IP范围，不要包含静态地址，DHCP服务器必须是静态的,mail,dns
	default-lease-time 21600;		 #租用时间，秒
	max-lease-time 43200;			#最多租用，如有人抢地址就释放，一般不会抢的
	host mail{				#mail 是主机名 静态地址  ping mail.chinaitlab.com
	
		hardware ethernet 12:34:56:AB:CD;   #如果是这个网卡就给它下面的地址，不要放在上面的IP范围内
		fixed-address 10.0.0.1;		  #不在range范围中有
	}

  }

  示例OK ,总是从小的向大的分配
--------------------
　
	default-lease-time 21600;		 
	max-lease-time 43200;
	option domain-name	"chu888";	
	option domain-name-servers 10.0.0.254;   
	option routers		10.0.0.254;
	option  broadcast-address 192.168.1.1;
	option  perform-mask-discovery on;
	ddns-update-style none;
	group
	{
		subnet 192.168.4.0 netmask 255.255.255.0
		{
			range dynamic-bootp 192.168.4.2 192.168.4.200;
		}
		host printer
		{
			hardware ethernet 00:00:80:F8:07:10;
			fixed-address 10.0.0.1;
			option host-name "printer server"
		}
	}

--------

vi /etc/dhcpd.conf 只可这个目录，可从安装目录中复制、改
touch /var/state/dhcp/dhcpd.leases   #释放IP信息
rpm包的是 /var/lib/dhcp/dhcpd.leseas	
/var/log/message  有日志放了哪个地址

dhcpd  启动  局域网中只能有一个DHCP服务
grep bootp /etc/services  得知 监听端口 67　　


windows中 (ipconfig /renew， ipconfig /all 显示DNS suffix:chainitlib.com配置的,DCHP Server是哪个 )
dhclient eth0 重新获得IP
　
route -n 来看 或者用netstat -r

at now+1minutes 回车后
	service network restart　　##SSH会断
ctrl+d结束

======================Kea======================
www.isc.org   
	 Kea 为了替换 DHCP
	
	

============openSSL ==============================================
JKS(JavaKeysotre)格式和PFX(PKCS12) 
PFX常用于Windows IIS服务器 , JKS常用语JAVA类的WEB服务器

根据私钥pfx生成公钥crt
openssl pkcs12 -in myssl.pfx -nodes -out server.pem (像Base64的明文)
openssl rsa -in server.pem -out server.key
openssl x509 -in server.pem -out server.crt   (.crt是像Base64的明文的公钥文件)

1.创建根证私钥
openssl genrsa -out root-key.key 1024

2.创建根证书请求文件
openssl req -new -out root-req.csr -key root-key.key -keyform PEM    (对-key参数,默认PEM,可选DER)  
#有交互Country Name ,Province ,City,Organization,Organizational Unit,Common Name,Email , 最小4位challenge password,company name

3.自签根证书
openssl x509 -req -in root-req.csr -out root-cert.cer -signkey root-key.key -CAcreateserial -days 3650    (.crt是像Base64的明文的公钥文件)

4.导出p12格式根证书
openssl pkcs12 -export -clcerts -in root-cert.cer -inkey root-key.key -out root.p12 
#输入密码,有确认的
#-clcerts only output client certificates (not CA certificates)

5.生成root.jks文件
keytool -import -v -trustcacerts -storepass 123456 -alias root -file root-cert.cer -keystore root.jks 

如要二制的.cer文件,要转换pem到der
openssl x509 -in root-cert.cer -inform PEM -out root-cert_b.cer -outform DER 

----------------方式二
1) 创建私钥
openssl genrsa -out private_key.pem 1024  (像Base64的明文)

2) 创建证书
openssl req -new -out req.csr -key private_key.pem  -keyform PEM  (对-key参数,默认PEM,可选DER)  
#有交互Country Name ,Province ,City,Organization,Organizational Unit,Common Name,Email , 最小4位challenge password,company name

3) 自签署证书
openssl x509 -req -in req.csr -out public_key.der -outform der -signkey private_key.pem -days 3650

以上三步也可简化为一个命令
openssl req -x509 -out public_key.der -outform der -new -newkey rsa:1024 -keyout private_key.pem -days 3650 
----

openssl-1.0.1k.tar.gz
$ ./config    可选的 --prefix
$ make
$ make test
$ make install



==============Git 安装配置 使用
Git四种协议
1.本地
2.git://
3.http://
4.SSH

SmartGit界面UI 

---windows版本
Gitblit (Java开发的) http://gitblit.github.io/gitblit/ ，有管理界面,使用http协议(可以为visual studio 2015用,不支持ssh)

Google Code项目 msysgit 中的Git 和 msysGit-fullinstall 有 GitGUI ,C:/Program Files (x86)/Git/doc/git/html

--------GitLab
只有linux版本,有管理界面,可LDAP登录
有收费版本
免费版本下载 https://packages.gitlab.com/gitlab/gitlab-ce 
gitlab-ce-12.7.6-ce.0.el7.x86_64.rpm
gitlab-ce-12.7.6-ce.0.sles15.x86_64.rpm  是openSUSE-15.1的版本
有docker版本 gitlab-ce

systemctl  disable gitlab-runsvdir.service

--
对GitLab进行重配置 （这一步也是启动 GitLab） 
sudo gitlab-ctl reconfigure  使用ruby来安装,默认安装在 /opt/gitlab目录下,默认使用自带的postgresql


查看启动状态 
sudo gitlab-ctl status 发现有redis,nginx

停止服务
gitlab-ctl stop

gitlab-ctl restart

看日志
gitlab-ctl tail
gitlab-ctl tail  postgresql
/var/log/gitlab/nginx/access.log


http://127.0.0.1/ 首次进入页后提示修改密码,至少8个字符(为root用户)
http://<外网IP>/也可仿问

先建立group,可选择图标(Group avatar),再建立项目时就可选择建立的组名,做为git地址的context
为建立的项目加用户,左侧Settings->Members选择用户,在role permission中选择Developer

LDAP用户支持 Microsoft Active Directory ,Apple Open Directory 和 OpenLDAP ,389 Server(fedora项目)
默认没有开启LDAP支持
建立用户初始密码发邮箱,但要配置SMTP , /etc/gitlab/gitlab.rb 中搜索 smtp,ldap
# gitlab_rails['smtp_enable'] = true
# gitlab_rails['smtp_address'] = "mail.domain.com"
# gitlab_rails['smtp_port'] = 25
# gitlab_rails['smtp_user_name'] = "root"
# gitlab_rails['smtp_password'] = "root123"

# gitlab_rails['ldap_enabled'] = false
#....
#	   host: '_your_ldap_server'
#     port: 389
#     uid: 'sAMAccountName'
#     bind_dn: '_the_full_dn_of_the_user_you_will_bind_with'
#     password: '_the_password_of_the_bind_user'

修改配置后 gitlab-ctl reconfigure
--------



%HOMEPATH%\AppData\Local\Programs\Git\mingw64\bin\git.exe

Git-2.15.1.2-64-bit.exe 如非管理员安装，默认安装在 %HOMEPATH%\AppData\Local\Programs\Git
 选择使用notepad++为默认编辑器 
 
 
C:\Program Files\Git\mingw64\etc\gitconfig
	[credential]
		helper = manager
%HOMEPATH%\.gitconfig
	[gui]
	
C:\Program Files\Git\mingw64\share\doc\git-doc 下有文档
 user-manual.html
 
 
---源码版本安装
make configure
./configure 
make all
make install

----

http://git-scm.com/book/zh

1. 安装目录/etc/gitconfig文件,使用 git config --system  读写
2. 用户主目录.gitconfig 文件,使用 git config --global 读写 , git config --global -e 直接打开文件编辑
3. 工作目录中.git/config 文件 		有保存项目的地址

gitconfig 文件中  #或者;  是注释
[user]
	name = user
	email = userId@sina.com
	
配置的是你个人的用户名称和电子邮件地址,提交时用


git config --global core.autocrlf true # AutoCRLF 提交时转换为LF，检出时转换为CRLF 
git config --global core.autocrlf false #提交检出均不转换 (常用)
git config --global core.autocrlf input #提交时转换为LF,检出时不转换

git config --global core.safecrlf warn #提交包含混合换行符的文件时给出警告

$ git config --global user.name "User"  (windows下是保存在用户主目录.gitconfig 文件)
$ git config --global user.email userId@example.com
$ git config --global core.editor vi		文本编辑器
$ git config --global merge.tool vimdiff	差异分析工具
git config --global alias st "status"  定义st 是status 的别名,就可以用git st=git status

git config --list 检查已有的配置信息, 会看到重复的变量名,来自不同的配置文件,实际采用的是最后一个
git config user.name 查配置

git help -a 查看一级帮助 
git config 查看二级帮助  , git help commit 打开浏览器 C:/Program Files/Git/mingw64/share/doc/git-doc/git-commit.html

cd project1
git init  初始化Git,生成.git目录 
如客户端使用ssh协议，linux服务器要使用git init --bare，客户端才可以push
--bare 不再生成.git目录,而是只生成.git目录下面的版本历史记录文件


就可,提交 git add *.c  再  git commit  -m 'initial project version'  
git commit -a -v ( -a 已经跟踪的文件不用add了, -v 先看一下差异,可以写comment),实际上是提交到本地,如果要提交到远程用 push

git commit --amend 如最后一次提交后，但没有push，会打开vi 可以修改这次comment
如git clone 的地址是https时报SSL问题，可以关闭验证 git config --global http.sslVerify false

git clone git://github.com/schacon/grit.git mygrit
#  操作基本上相当于 git init 加 git fetch
fetch 本地仓库中还没有的数据


git status  显示有没有新加文件,或者要提交的文件
 
--创建一个名为 .gitignore 的文件,列出要忽略的文件模式
#忽略所有以 .o 或 .a 结尾的文件
*.[oa]		

# 但 lib.a 除外
!lib.a

#忽略所有以swp结尾的文件,vi生成的
*swp

build/
#最后跟斜杠（/）说明要忽略的是目录 
--
git diff hello.c

rm hello.c
git rm hello.c
git rm -r --cached dir_name #指定目录中的全部文件 --cached表示从index中删除，显示为删除图标，但文件保留

git mv file_from file_to  #改名

git log 历史版本
git log -p 2
-p 显示内容差异,-2 仅显示最近的两次更新
git log --author=user01 --grep COMMENT_BUG_ID
git log --after="2021-01-20 10:44:00" 指定日期之后的

git log origin/xx_branch 显示服务端指定分支的历史记录
git log --graph 显示图

git remote -v  显示有名字为 origin , clone后就有
git remote show origin

git remote add pb git@192.168.0.184:/opt/my_git_server/project1
git fetch [remote-name]

git pull 为了合并分支,就是fetch加merge
git push [remote-name] [branch-name]
git push origin master   #master是哪个分支
git push origin HEAD 可以把本地的git reset xxx  的HEAD修改push到服务器上
git push --set-upstream origin feature/v2.0
  
git remote rm pb
 
----服务器上部署 SSH 协议
先把现有仓库(init过的)导出为裸仓库,裸仓库的目录名一般以 .git 结尾
git clone --bare project1 project1.git
.git目录用于放在服务中对外使用,目录有写权限,就有推送权限


建立git用户时指定SHELL 为 /usr/local/bin/git-shell 
useradd -s /usr/local/bin/git-shell git (可设置完成后再修改)

用户机 ssh-keygen 会要求输入密码(可不输)
传给对方的公钥 ~/.ssh/id_rsa.pub 

服务器收到用户机的公钥后 追加写入 ~/.ssh/authorized_keys(权限) 文件,用户就可(使用建立密钥时的密码或无)连接自己机器


git clone git@192.168.0.184:/opt/git_server/project1.git ##只对设置密钥密码为空时才可(linux客户端)

----服务器上部署 哑（Dumb） HTTP 协议 
web 服务器仅把裸版本库当作普通文件来对待,支持post-update 的挂钩

cd /var/www/htdocs/
$ git clone --bare /path/to/git_project gitproject.git
$ cd gitproject.git
$ mv hooks/post-update.sample hooks/post-update
$ chmod a+x hooks/post-update

  
客户端
## git clone http://192.168.0.184:80/project1.git 


---Git 本地协议  
git remote add local_proj /opt/git/project.git 

---Git 协议，没有授权机制
9418端口,先创建 git-daemon-export-ok 文件,一旦允许该操作，网络上任何一个知道项目 URL 的人将都有推送权限 
如何做,为开源匿名只读,要有独的用户验证机制

----
git branch 查看branch 有 *master
git branch --merged 查看哪些分支已被并入当前分支
git branch --no-merged 查看尚未合并的工作
git branch -d testing 合并后就没用了,删本地分支


git tag -l 查看tag
git remote -v 显示对应的克隆地址


当本地有git版本,服务器上有git版本,都是新建立, 从本地git版本 push报错时
git fetch  提示新branch是  master -> origin/master
git branch 显示的是*master
git status 
git checkout origin/master
git checkout master 切换到master，或其它分支
git checkout <git id> 可以整个项目切换到这个分支，如回到原来分支 git checkout <分支名>
git merge  <服务器git版本最后的id>


---建分支

git clone -b myBranch ssh://git@xx.com/project.git  直接从分支拉代码

$ git checkout -b myBranch  提示切换到新的分支了
它是下面两条命令的简写 
$ git branch myBranch
$ git checkout myBranch
git push --set-upstream origin myBranch
开发做修改后

把myBranch 合并到master
git checkout master
git merge myBranch 本地分支，也可远程分支 (git merge remotes/origin/myBranch  ) 如有冲突提示符变  (master|MERGING)，如要取消修改git reset 到(master)

合并没用了，就可以删了
git branch -d myBranch 
git branch -r -d origin/myBranch 
git push origin :myBranch

远程没有有remote_branch分支并，本地已经切换到local_branch
git push origin local_branch:remote_branch
git push --set-upstream origin <branch_name>
git push origin myBranch:myBranch
git push <远程主机名> <本地分支名>:<远程分支名>
git remote show 查远程主机名是什么

git push -u origin master
命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了

git branch -a 可以查看到 remotes/origin 开头的远程分支
git branch -r 查看远程分支

git pull <远程主机> <远程分支>:<本地分支>
git pull origin <远程分支名>:<本地分支名>
git pull origin <远程分支名>
git pull 将与本地当前分支同名的远程分支 拉取到 本地当前分支上


git show <commit-id> 显示文件内容的差异

NetBeans 切换分支生成的命令 git branch --track performance origin/performance

---建tag 
轻量级标签就像是个不会变化的分支
	git tag v1.4-lw
	git tag
	
附注标签  可以加说明   
	git tag -a v1.4 -m 'my version 1.4'
	git show v1.4
	
默认情况下git push 并不会把标签传送到远端服务器上
tag要单独puhs用 git push origin [tagname]
	git push origin  v1.4

	git checkout -b branch-v1.4 v1.4  基于tag建立分支
	
	查tag信息
	git log v1.0
	git show v1.0
	
	
	git tag -d <tag>
	-d
	--delete
---
如果想要恢复到修改之前的状态就使用，即自己的修改不想要了(Totorise SVN的revert某个文件)
git checkout  文件名
 
git reset --mix HEAD^  表示最近一次commit但没有push的，从提交记录中删除，文件还是被git管理，文件修改的内容还在
git reset --soft HEAD^  表示最近一次commit但没有push的，从提交记录中删除，但这批文件不被git管理，文件修改的内容还在 
git reset --hard HEAD^  表示最近一次commit但没有push的，从提交记录中删除，但这批文件不被git管理，文件修改的内容不存在
git reset --hard  <commit Id> 已经commit没有push做取消 ,<commit Id>是回到那次提交的状态，不是对某个文件，全局的  (新加的文件不会被删除)

已经commit的但没有push的 一些文件不想做commit
git reset --soft HEAD^ 提示有git restore --staged <file>做unstage 即不提交这些文件

git revert HEAD

git查看某个文件的修改历史
git log --pretty=oneline 文件名


的分支上开发一半, 发现原有的分支上有紧急的bug， 使用'git stash'就可以将你当前未提交到本地（和服务器）的代码推入到Git的栈中 
放心的修 Bug，等到修完Bug，提交到服务器上后，再使用'git stash apply'将以前一半的工作应用回来

多次 'git stash'命令后
'git stash list'命令可以将当前的Git栈信息打印出来，
如使用'git stash apply stash@{1} 执行后不删除
可以使用'git stash clear'来将栈清空
git stash save xx_name 起个名字，只为看，drop/apply 只可用ID
git stash drop stash@{1}   删除某一个
git stash pop 从最顶取后删除



git cherry-pick 可以另一个分支的某一个修改 合并到当前分支中，可能会有冲突
git cherry-pick <另一分支的commit id>

git rebase --abort 放弃换基，回到rebase之前的状态，之前提交的不会丢失
git rebase --skip
git rebase --continue
git pull --rebase

Git 本地的多个commit合并成一个
	git rebase -i <after-this-commit> ## [-i | -interactive]进入vi显示所有后面提交
		有提示命令s,squash <commit> = use commit,but meld into privous commit(meld合并的意思)即从第二行开始修改命令为squash,使用:wq保存退出
		又进入vi界面,提示修改comment,把多个commit修改为一个
	#git rebase -i HEAD~5
rebase也可做类似分支的合并

git format-patch HEAD ^^ #最近2次commit的做 patch,HEAD~10表示最近10次
git am --abort (am=apply mailbox) 停止应用patch

 

----  github操作提示
…or create a new repository on the command line

echo "# Record" >> README.md 
git init
git add README.md
git commit -m "first commit"
git remote add origin https://github.com/userId/Record.git
git push -u origin master

…or push an existing repository from the command line

git remote add origin https://github.com/userId/Record.git
git push -u origin master

--网页上建立github的项目Record,自己的操作记录
cd C:\temp\Record
git init
git add Record
git commit -m "xxx record version"
git remote add origin https://github.com/userId/Record.git
git push -u origin master

如果在空目录中取代码 git clone https://github.com/userId/Record.git
修改更新,加新文件
git config --global user.email "userId@sina.com"   (windows中保存在用户主目录/.gitconfig)
git config --global user.name "User"
git add *
git commit  -m "2017-05-18 record version" 
git push 弹出UI 要输入用户名密码   (windows下密码保存在控制面板-》用户-》Creddentail manager)

删文件
git rm Not-Offen/Struts-2.x.java
git push

如用TortoiseGit ->Check for modifications 中 Commit 或者revert
			->push

github上的代码库时，如果使用SSH链接
ssh-keygen 然后系统提示输入文件保存位置等信息，连续敲三次回车即可，生成的SSH key文件保存在中~/.ssh/id_rsa.pub
拷贝 .ssh/id_rsa.pub文件内的所以内容，将它粘帖到github帐号管理中的添加SSH key界面中
(登录github->右上方的Accounting settings图标->SSH key->Add SSH key->填一个你自己喜欢的名称即可，然后将上面拷贝的~/.ssh/id_rsa.pub文件内容粘帖到key一栏，在点击“add key”按钮就可以了)
 
----  github

----- git 清除已保存的密码 测试OK  
git config --system --unset credential.helper

---
Git\mingw64\etc\gitconfig 的文件，打开文件
[credential]
XXXX=manager
然后我直接修改，文件吧文[credential] XXXX=manager 直接删除
---
TortoiseGit -》 setttings->Git->点edit systemwide gitconfig按钮

---Git 服务端钩子
项目中的 .git/hooks 目录 放(任何语言)可以执行脚本
 
来自客户端的推送操作时，最先被调用的脚本是 pre-receive,从标准输入获取,如果它以非零值退出，所有的推送内容都不会被接受

update 脚本 ,不会从标准输入读取内容，而是接受三个参数,当同时向多个分支推送内容，pre-receive 只运行一次，相比之下 update 则会为每一个被推送的分支各运行一次

post-receive 挂钩在整个过程完结以后运行,标准输入数据,以用来更新其他系统服务或者通知用户


--示例--vi hooks/post-receive
#/usr//bin/bash
echo "$(date) to /root/git_post_log"
echo $(date) >>/root/git_post_log
wget -q -O - http://192.168.114.13:8080/jenkins/generic-webhook-trigger/invoke?token=mytoken


开源项目 webhook, github上可配置webhook,在push后,可以配置请求指定URL(webhook项目可以启动一个服务，可以配置一个可执行的文件)


============== 上 Git 
===========phpmyadmin-5.0.1
openSUSE-leap-15.1的yast 自带 phpMyAdmin包
	直接安装在/srv/www/htdocs/phpMyAdmin目录下 ,有配置 /etc/apache2/conf.d/phpMyAdmin.conf
	

手工下载包放 /srv/www/htdocs/ 目录

-- vi /etc/apache2/conf.d/phpmyadmin.conf 引用目录测试失败???
Alias  /phpmyadmin "/software/linux_software/phpMyAdmin-5.0.1-all-languages"
<Directory "/software/linux_software/phpMyAdmin-5.0.1-all-languages">
 	Options Indexes FollowSymLinks MultiViews
	AllowOverride all
	Require all granted
	php_admin_value upload_max_filesize 128M
	php_admin_value post_max_size 128M
	php_admin_value max_execution_time 360
	php_admin_value max_input_time 360 
</Directory>



----mailx 一个邮件客户端工具 
测试使用 echo "Mail Content" | mailx -s "Mail Subject" -a /tmp/attach.txt xx@163.com 测试成功(可没有DNS服务,使用/etc/hosts)
日志在  /var/log/mail ,journalctl -xeu postfix 或 journalctl -u postfix --since today


vi /etc/mail.rc  (mailx包中的)
...
#set from=dellx@domain.com smtp=smtp.domain.com
#set smtp-auth-user=dell@domain.com smtp-auth-password=123
#set smtp-auth=login

#以下测试可以登录sina.com并发送到163.com
set from=user1@sina.com smtp=smtp.sina.com
set smtp-auth-user=user1@sina.com smtp-auth-password=123
set smtp-auth=login
 
-----
===========postfix===========================
----源码安装 postfix 3.5.10
make 提示 要先安装  db*-devel 

---源码安装 postfix
依赖于PCRE , ./configure  && make && make install 安装在/usr/local下 ,
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
建立用户,组 
groupadd  postdrop
useradd postfix

make && make install 会提示输入很多目录,都有默认值 
install_root: [/]
tempdir: 
config_directory: [/etc/postfix]
command_directory: [/usr/sbin]
daemon_directory: [/usr/libexec/postfix]
data_directory: [/var/lib/postfix]
html_directory: [no] 
mail_owner: [postfix]
mailq_path: [/usr/bin/mailq] 
manpage_directory: [/usr/local/man]
newaliases_path: [/usr/bin/newaliases] 
queue_directory: [/var/spool/postfix]
readme_directory: [no]
sendmail_path: [/usr/sbin/sendmail]
setgid_group: [postdrop]


--- 主配置文件是/etc/postfix/main.cf
 $ 来引用该变量，  等号两边需要有空格字符  
如果变量有两个以上的设置值，就必须用逗号“，”或者空格符“ ”将它们分开

mail_owner = postfix
queue_directory = /var/spool/postfix

myhostname = smtp.domain.com    #要修改的,有配置 myhostname = localhost
mydomain = domain.com   			 #要修改的

myorigin = $mydomain    #要放开的，将发信地址“@”后面的部分设置为域名

inet_interfaces = all   #默认为all，如localhost表明只能在本地邮件主机上寄信  ,一般应是all
 
inet_protocols = all   #默认为ipv4，如果支持ipv6，则可以为all 

mydestination = $myhostname, localhost.$mydomain #这是默认值，参数非常重要，因为只有当发来的邮件的收件人地址与该参数值相匹配时,才自己接收

mynetworks=192.168.16.0/24  #要修改的，则表示这台邮件主机只转发子网192.168.16.0/24中的客户端所发来的邮件，而拒绝为其他子网转发邮件。
#mynetworks = hash:/etc/postfix/network_table

mynetworks-style = subnet  #默认为subnet，可选的有class(A,B,C类地址), host ,subnet

通常，用户不设置mynetworks-style参数，而直接设置mynetworks参数。如果这两个参数都进行了设置，那么mynetworks参数的设置有效


#relay_domains = $mydestination 
relay_domains = $mydestination, hash:/etc/postfix/relay
则表示任何由域 $mydestination  发来的邮件都会被认为是信任的，Postfix会自动对这些邮件进行转发。（relay 转送）

home_mailbox = Maildir/  #默认是关闭的，相对于/var/spool/mail/user 或 /var/mail/user 目录（/var/mail 链接到/var/spool/mail）
message_size_limit = 0 #默认值0
mailbox_size_limit = 0 #默认值0
---

要查看Postfix的当前主要配置postconf -n （只看显示的配置）
root用户执行 systemctl restart postfix 或者  postfix reload 

virtual_alias_domains 用来指定虚拟别名域的名称 
virtual_alias_maps = hash:/etc/postfix/virtual #默认值，没放开 用来指定含有虚拟别名域定义的文件路径。

/etc/postfix/virtual 文件内容,第一列虚拟域或者虚拟域用户 ,  第二列无@ 表示本地linux用户
@dzxx.cn  @gdvcp.net
admin@example.com  lbt
st0321@example.com  st0321001，st0321002
daliu@example.com  lbt，liu6812@163.com

执行:
postmap /etc/postfix/virtual   生成 virtual.db
postfix reload


----
用户别名 http://www.postfix.org/postconf.5.html#alias_maps
postconf -d | grep alias (-d 表示 default 默认配置)

alias_maps = hash:/etc/aliases   #默认配置
alias_database = hash:/etc/aliases #默认配置

示例:/etc/aliases，
st0322:  st0322001，st0322002，st0322003，st0322004
st0323:  :include: /etc/mail/st0323
jcz01:  jczliuming
lm01:  jczliuming，liuming86@163.com

示例:/etc/mail/st0323
st0323001，\
st0323002，\
st0323003，\
 
postalias /etc/aliases          
postfix reload

---SASL(Simple Authentication and Security Layer)
http://www.postfix.org/SASL_README.html


SMTP服务要做登录认证,Postfix SMTP 支持 Cyrus SASL 和 Dovecot SASL 两个实现

默认使用Cyrus SASL(C和Perl开发),如要使用 Dovecot SASL(C开发，可使用mysql,postgresql,sqlite,有对应的backend-xx-rpm包) 	/etc/postfix/main.cf 中 做修改 
	smtpd_sasl_type = dovecot

postconf -a 查看服务端在编译时支持哪个
postconf -A  查看客户端支持哪个


smtp   端口 25
SMTPS  端口 465

imap   端口 143
imaps  端口 993  即imap的 TLS/SSL 
pop3s  端口 995  即pop3的 TLS/SSL 
pop3   端口 110

--/etc/postfix/main.cf 
smtpd_sasl_type = dovecot #或 cyrus
smtpd_sasl_security_options = noanonymous
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtpd_sasl_auth_enable = yes			服务端
smtp_sasl_auth_enable = yes			客户端

-- vi /etc/postfix/sasl_passwd
domain.com user1:pass2


zypper install dovecot 后
--vim /etc/dovecot/dovecot.conf
!include conf.d/*.conf

#listen = *, ::
#login_trusted_networks =

--vim /etc/dovecot/conf.d/10-auth.conf
#disable_plaintext_auth = yes
auth_mechanisms = plain login

--vim /etc/dovecot/conf.d/10-mail.conf
mail_location = maildir:~/Maildir

--vim  /etc/dovecot/conf.d/10-master.conf
unix_listener /var/spool/postfix/private/auth {
  mode = 0666
  user = postfix
  group = postfix
}

--vim /etc/dovecot/conf.d/10-ssl.conf
#ssl = yes

systemctl start dovecot


---TLS
http://www.postfix.org/TLS_README.html

smtpd_use_tls = no
#smtpd_tls_loglevel = 0
smtpd_tls_CAfile =
smtpd_tls_CApath =
smtpd_tls_cert_file =
smtpd_tls_key_file =
smtpd_tls_ask_ccert = no
smtpd_tls_received_header = no


smtpd_tls_auth_only = yes


#---没有 saslauthd testsaslauthd 命令??
saslauthd -v 查看所支持的密码验证机制 

/etc/sysconfig/saslauthd中
MECH=shadow    ###直接用/etc/shadow,  ,pam /etc/pam.d/imap

/etc/init.d/saslauthd start
saslauthd -a pam /shadow  这是OK的

testsaslauthd -u 用户 -p  密码  ##测试,日志文件
#---

main.cf文件中
smtpd_sasl_auth_enable = yes
smtpd_sasl_local_domain = '' ##默认的
smtpd_recipient_restrictions = permit_mynetworks,permit_sasl_authenticated, reject_unauth_destination
broken_sasl_auth_clients=yes
smtpd_client_restrictions = permit_sasl_authenticated
smtpd_sasl_security_options = noanonymous  #默认的



（3）smtpd_recipient_restrictions：表示通过收件人地址对客户端发来的邮件进行过滤。通常有以下几种限制规则。

permit_mynetworks：表示只要是收件人地址位于mynetworks参数中指定的网段就可以被转发邮件。

permit_sasl_authenticated：表示允许转发通过SASL认证的邮件。
reject_unauth_destination：表示拒绝转发含未信任的目标地址的邮件。


就必须确保/usr/lib/sasl2/smtpd.conf文件中的内容为：pwcheck_method: saslauthd

测试 telnet localhost 25

telnet localhost 80
ftp> get index.html

输入ehlo 返回当前Postfix所支持的认证方式 两行AUTH ......


cyrus-imapd-2.4(redhat-EL7.6 光盘中有的 lm_sensors)
另一个 imap 服务器是dovecot-2.2.x redhat-EL7.6 光盘有的

cp /usr/local/dovecot/etc/dovecot-example.conf /usr/local/dovecot/etc/dovecot.conf
可以直接用dovecot就可以启动与xinetd同
/usr/local/libexec/dovecot/imap-login(或者用pop3-login可加--ssl)

vi /etc/dovecot.conf在protocols = imap imaps 后添加pop3 pop3s 
  

/etc/yum.conf 中keepcache=1是保留文件,0是删
		cachedir=/var/cache/yum

service cyrus-imapd start
cyradm -u cyrus localhost

cyradm --user cyrus --server localhost --auth plain

main.cf 中加入
mailbox_transport = lmtp:unix:/var/lib/imap/socket/lmtp

/etc/sysconfig/cyrus-imapd：用于启动cyrus-imapd服务的配置文件。
/etc/cyrus.conf：是cyrus-imapd服务的主要配置文件，其中包含该服务中各个组件（IMAP、POP3、sieve和NNTP等）的设置参数。
/etc/imapd.conf：是cyrus-imapd服务中的IMAP服务的配置文件

service cyrus-imapd start
chkconfig cyrus-imapd on

源码安装cyrus-imapd
===看doc/index.html===
env CPPFLAGS=-I/usr/local/include LDFLAGS=-s ./configure --with-bdb=/usr/local/bdb  
( 要安装Berker DB  ####./configure --with-bdb=/usr/local/bdb --with-sasl=/usr/local/sasl2/ --with-openssl=/usr/local/openssl)--with-cyrus-prefix=/usr/cyrus  --prefix=

make depend
make all CFLAGS=-0  ###不成功
cd perl(cyrus-imapd-src)安装 perl


cyrus-imapd
http://cyrusimap.web.cmu.edu/downloads.html

sasl2.1.22是有的
cyradm 

ln -s /usr/lib/perl5/5.10.0/Shell.pm /usr/lib/perl5/site_perl/5.10.0/Cyrus/IMAP/Shell.pm   ####Cyrus/IMAP/Shell.pm 部分是建的

=====
makedepend
http://www.t2-project.org/packages/makedepend.html

tcl
文档上依赖的
makedepend
perl 5
openssl 0.94
libsasl
libwrap  ftp://ftp.porcupine.org/pub/security/   tcp_wrapper7.6    光盘中有的 默认是安装的
net-snmp http://www.net-snmp.org/download.html   net-snmp-5.4.1.2  光盘中有的 默认是安装的
推荐 flex,gcc
--with-bdb=
--with-libwrap=
--with-snmp=
--with-sasl=

要cyrus用户

passwd cyrus


Cyrus-IMAP的邮件信箱位于/var/spool/imap目录下

关键字user表示信箱类型为用户信箱



 Postfix queues.默认是 [/var/spool/postfix]
不可queue management 组默认postdrop



===========上 postfix==========================
===========postfixadmin
https://github.com/postfixadmin/postfixadmin

一个 php + mysql/postgresql 的管理工具 
可以配置 Dovecot 
 

zypper install postfixadmin

#启用POSTFIXADMIN标志，为/etc/apache2/conf.d/postfixadmin.conf文件使用
a2enflag POSTFIXADMIN 


--mysql
create database postfix character set utf8 collate utf8_bin;
create user postfix@localhost identified by 'postfixadmin';
grant all privileges on postfix.* to postfix@localhost ;
ALTER USER postfix@localhost IDENTIFIED WITH mysql_native_password   BY 'postfixadmin';

create user postfix@'%' identified by 'postfixadmin';
grant all privileges on postfix.* to postfix@'%' ;
ALTER USER postfix@'%' IDENTIFIED WITH mysql_native_password   BY 'postfixadmin';

vi /etc/postfixadmin/config.inc.php 配置mysql
 	$CONF['configured'] = true;
	$CONF['database_type'] = 'mysqli';
	$CONF['database_host'] = 'localhost';
	$CONF['database_user'] = 'postfix';
	$CONF['database_password'] = 'postfixadmin';
	$CONF['database_name'] = 'postfix';


===========上 postfixadmin

=========== cyrus-imapd 是一个 邮件,联系人和日历服务 
使用C和perl
https://cyrusimap.org/ 最新版本3.0

支持IMAP4和 pop3 (只可读用户的INBOX箱)

# rpm -ivh imap-2002d-3.i386.rpm --nodeps
要修改/etc/xinetd.d/imap文件把disale=yes 改为no,会有143端口监听
telnet localhost 143 来测试可能还 要libcrypto.so.4

cyrus
./configure --with-dbdir=/usr/local/BerkeleyDB.4.6/
	###--with-bdb-libdir or --with-bdb-incdir configure options.
成功编译后，make depend－》make all CFLAGS=-O(看文档的,可能不行的)

===========dovecot 是一个 Imap 和 Pop3  服务
https://www.dovecot.org/
https://wiki2.dovecot.org/
使用C开发,最新版本2.3.9
zypper install dovecot 有 backend-sqlite,backend-mysql,backend-pgsql

---------squirrelmail
http://squirrelmail.org/
2011 是最后更新版本 1.4.22


---------OpenwebMail 
http://www.openwebmail.org/
2008 是最后更新版本 2.53 	

安装目录/var/www/html/和/var/www/cgi-bin/

cd /var/www/cgi-bin/openwebmail［Enter］　　// 进入openwebmail目录
　　　./openwebmail-tool.pl -init［Enter］　　// 软件包初始化
		当屏幕上显示"Please hit 'Enter' to continue or Ctrl-C to break."时，单击回车键继续。


================ HAProxy 可用于放在Ngnix的前方
支持数以万计的并发连接, 使用事件驱动, 单一进程 ,不能做缓存

支持四层负载与七层负载
 
https://www.haproxy.org/download/2.0/src/haproxy-2.0.5.tar.gz  		2019-08-16
已经有下载地址就不需要翻墙了


文档
https://cbonte.github.io/haproxy-dconv/


源码doc目录也有文档,examples 有些示例配置
 
openSUSE-15.1 yast 有版本是1.8.17 ，rpm包 带 /etc/haproxy/haproxy.cfg
 
源码linux下编译

$ make clean
$ make -j $(nproc) TARGET=linux-glibc \
                USE_OPENSSL=1 USE_ZLIB=1 USE_LUA=1 USE_PCRE=1 USE_SYSTEMD=1
                
$ sudo make install

提示找不到 systemd/sd-daemon.h  (安装 systemd-devel)

nproc 命令显示CPU有多少核

安装后只有 
/usr/local/sbin/haproxy   
/usr/local/share/man/man1/haproxy.1
/usr/local/doc/haproxy 目录

---haproxy.cfg
global
	log	/var/log	daemon  #其中 daemon 是syslog中的24种 facilities之一,可local0,local1
#以下swarm提示的配置
# Configure HAProxy to listen on port 80
frontend http_front
   bind *:80
   stats uri /haproxy?stats
   default_backend http_back

# Configure HAProxy to route requests to swarm nodes on port 8080
backend http_back
   balance roundrobin
   server node1 192.168.99.100:8080 check
   server node2 192.168.99.101:8080 check
   server node3 192.168.99.102:8080 check
   
启动服务 systemctl start haproxy  
看日志 systemctl -u haproxy.service  可缩写为 systemctl -u haproxy

 


============== Nginx 比 Squid 强 
Nginx Plus 收费版本  https://nginx.com
Nginx Controller 是为 Nginx Plus 
Nginx App Protect 是为 Nginx Plus 
Nginx Amplify 是Monitor

有open Source版本 https://nginx.org/
最新稳定版本1.18.0(2020-10)  有windows 版本.zip文件 

​N​e​t​S​c​a​l​e​r​ 和 A10 EX Series  类似于F5,Radware 的硬件 ,负载均衡器
Apache的 mod_proxy和mod_cache结合使用也可以实现对多台app server的反向代理和负载均衡，但是在并发处理方面apache还是没有 nginx擅长


nginx 有一个 master 进程(读配置,维护worker进程) 和几个 worker进程(处理请求),基于OS的事件模型,默认进程数是CPU的核数

流量控制 
URL rewrite：URL重写
reverse proxy：反向代理
做缓存服务器  
实现对web服务的负载均衡
安装第三方插件，实现健康状态监测


源码编译,要C++编译器 yum list| grep gcc-c++, 依赖于  PCRE (Perl Compatible Regular Expressions)库(不是2版本) 

http://nginx.org/packages/ 有二进制包
http://nginx.org/packages/sles/15/x86_64/RPMS/
http://nginx.org/packages/centos/7/x86_64/RPMS/nginx-1.14.0-1.el7_4.ngx.x86_64.rpm  下载不了，网站问题
http://nginx.org/packages/rhel/7/x86_64/RPMS/nginx-1.14.0-1.el7_4.ngx.x86_64.rpm   下载OK
/usr/sbin/nginx ,man nginx 默认配置文件 /etc/nginx/nginx.conf

export PATH=/usr/sbin:$PATH
/var/log/nginx/error.log

也可/etc/yum.repos.d/nginx.repo 
[nginx]
name=nginx repo
baseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/
gpgcheck=0
enabled=1


默认安装在/usr/local/nginx,包括日志
./confure   --with-pcre=../pcre-8.41  (CentOS7自带 pcre-8.32 apache也是用这个,如用 --with-pcre=/usr   --with-zlib=/usr可能不行)
make
make install


/usr/local/nginx/sbin/nginx 启动  默认监听80端口
/usr/local/nginx/sbin/nginx -s stop   (-s signal)快速退出 ，reload重读配置文件 ，quit 和平退出
	stop — fast shutdown
	quit — graceful shutdown
	reload — reloading the configuration file,如果配置有错,就停止worker(处理完正处理的连接)进程
	reopen — reopening the log files
	-g 	daemon off; (-g 全局指令) 前台运行
	
/usr/local/nginx/sbin/nginx  -t 检查配置文件语法正确性
nginx -v  (version)
nginx -h  (help)
	-p prefix     : set prefix path (default: /etc/nginx/)
	-c filename   : set configuration file (default: /etc/nginx/nginx.conf)

--/usr/local/nginx/conf/nginx.conf   
每个server块以listen和server_name做区分

http{
	 server {  虚拟主机
		#listen       80;		注释的配置,就是默认的配置,默认监听80端口
		server_name  localhost;
		location / {  			是http请路径
				root   html;	是安装目录下的html目录
				index  index.html index.htm;
		 }
	 }
}


配置日志 https://docs.nginx.com/nginx/admin-guide/monitoring/logging/
http {
    log_format compression '$remote_addr - $remote_user [$time_local] '
                           '"$request" $status $body_bytes_sent '
                           '"$http_referer" "$http_user_agent" "$gzip_ratio"'; 
    server {
        gzip on;
        access_log /spool/logs/nginx-access.log compression;
        ...
    }
}


配置层级结构 http->server->location , events 和http同级

server   
{
	listen 8080;
	root /data/up1;   页面所在本地目录
	location / {
	}
}

#一个server下可有多个location
#一个http下可有多个 server,同时http和https
server {
	#location / {
	#	proxy_pass http://localhost:8080;   代理
	#}
 	location /myapp {
          alias   /usr/share/nginx/html; #要用alias才行,不能用root
          index  index.html index.htm;
	}
    }

	location /images/ {   请求 /images 对应本地/data/images/目录
		root /data;
	}
}
server 组中
location ~ \.(gif|jpg|png)$ {     #\.是转义,即以.gif,.jpg,.png结尾的的请求到指定目录去读
	root /data/images;
}
#location的第二列,正则表达式列(可选),如为~表示区分大小写,如为~*表示不区分大小写,如为=表示精确匹配,如为空或^~表示前缀匹配
 
upstream  nginx支持4种Load Balancing算法，要在http组中

1 Round Robin 轮询(默认)    有两台机器测试下来,每台机器执行两次后再切换机器,后端服务器down掉，自动切除。
	upstream backend {
	   server backend1.example.com;
	   server backend2.example.com;
	}
	location / {
		proxy_pass http://backend;
		proxy_buffering off; #默认on打开的,会使请求变慢 !!!!!
		
		#如代理websocket
		proxy_http_version 1.1;
		proxy_set_header Upgrade $http_upgrade;
		proxy_set_header Connection $connection_upgrade;
		proxy_set_header Host $host;
		
	}
2. Least Connections  ,最小的； 最少的little的最高级  
	upstream backend {
		least_conn;
		server backend1.example.com;
		server backend2.example.com;
	}

3 ip_hash 		每个请求按访问ip的hash结果分配，每个访客有固定的后端服务器，可以解决session问题
	upstream backend {
		ip_hash;
		server backend1.example.com;
		server backend2.example.com;
		server backend3.example.com down; 临时下线
	}
4 Generic Hash  按用户定义的key 如URL，按访问的url的hash结果分配，使每个url定向到同一个后端服务器，后端为缓存服务器比较有效。
	upstream backend {
		hash $request_uri consistent;  # ketama 一致性hash
		server backend1.example.com;
		server backend2.example.com;
	} 
Round Robin 方式参数 
	weight 		设定服务器权值 ,默认weight=1
		upstream backend {
			server backend1.example.com weight=5;
			server backend2.example.com;
			server 192.0.0.1 backup;#只有其它服务无效时才接收请求
		}
	   

固定Session方式  可使用上面的hash or ip_hash 
	
设置最大连接数 max_conns=3;超出放queue,如果其它工作进程打开了 keepalive 这个参数会被忽略
upstream backend {
    server backend1.example.com max_conns=3;
    server backend2.example.com;
    queue 100 timeout=70;
}

#被动健康检查 max_fails=3 fail_timeout=30s;
upstream backend {
    server backend1.example.com;
    server backend2.example.com max_fails=3 fail_timeout=30s;
    server backend3.example.com max_fails=2;
}
#活动健康检查 NGINX Plus 支持
http {
    upstream backend {
        zone backend 64k;
        server backend1.example.com;
        server backend2.example.com;
        server backend3.example.com;
        server backend4.example.com;
    }
    server {
        location / {
            proxy_pass http://backend;
            health_check;
        }
    }
}


示例
upstream http_server 
{
　　ip_hash;
　　server 127.0.0.1:9090 down;			--down暂时不参与负载，不进行反向代理
　　server 127.0.0.1:8080 weight=2;		--weight默认为1，weight越大，负载的权重越大
　　server 127.0.0.1:6060;
　　server 127.0.0.1:7070 backup;			--其它为down或者忙时候，请求backup机器
}    


nginx对静态资源 html静态页面缓存
location ~* .(ico|gif|jpg|jpeg|png|js|css|mp3|mp4) {
  root  /var/www/opkeep;
  expires 30d;
}



proxy_cache_path /data/nginx/cache keys_zone=one:10m;  用本地文件系统去缓存，keys_zone指定名字，和共享内存大小，用于存无数据
server {
	proxy_cache one;  用上面的名字
	location / {
		proxy_pass http://localhost:8000;
		proxy_read_timeout  60s; --for reading a response from the proxied server
		proxy_send_timeout 60s; -- for transmitting a request to the proxied server 没用
	}
}
---------
mginx -V 显示要带有  --with-http_stub_status_module
--nginx.conf
 location /nginx-status
 {
	stub_status on;
	access_log off; 
 }
--
http://127.0.0.1/nginx-status 返回数据
Active connections: 1   			#表示当前正在连接的个数
server accepts handled requests
 18 18 11 								
 #第1个server数字表示启动为止处理了多少个连接 ，第2个accepts数字表示启动为止多少次握手，第3个handled requests数字表示启动为止多少个请求
 #握手-连接 =0表示没有丢失
Reading: 0 Writing: 1 Waiting: 0  #当前

------上传文件大小限制
location / {
            root   html;
            index  index.html index.htm;
            client_max_body_size    500m;
  } 
-----自定义错误页
放在    server 下和 location /  下

	error_page  502   /50x.html;   #后台服务全部不可用时报 502 Bad Gateway
	location = /50x.html {
			root   html;  #windows下安装目录的html(linux是/usr/share/nginx/html)目录有/50x.html 
	}
	
------nginx  HTTP2
源码编译增加
--with-http_v2_module 选项
--with-http_ssl_module


------nginx Memcached
server {   
    location / {
        set            $memcached_key "$uri?$args";
        memcached_pass 127.0.0.1:11211;
        error_page     404 502 504 = @fallback;
    }
    location @fallback {
        proxy_pass     http://backend;
    }
}

 
------nginx  限流
max_conns=3;

添加limit_zone和limit_req_zone

添加limit_conn 和limit_req

1、limit_conn_zone

2、limit_req_zone

3、ngx_http_upstream_module

------nginx 白名单

------nginx https ssl 
TLSV1.2,TLS( Transport Layer Security )
http ssl 默认端口443
listen 443 ssl http2 default_server;  未试


------nginx cluster


------nginx  PHP fastcgi
CGI(Commmon Gateway Interface)
fastcgi应用程序(可以使用使用C/C++,python,PHP编写),
	单独的进程(出错不影响nginx)一直启动着(老的CGI是每次用的时候启动,性能差)
	apache是把cgi嵌入进来 (SAPI就是Server API 就是合并到服务器中,语言开发有限制,即apache的php模块只能用C/C++) 


#windows  打开php.ini配置修改
extension_dir = "D:/Program/php-7.4.3-Win32-vc15-x64/ext"
extension=mysqli
cgi.force_redirect = 1 
cgi.fix_pathinfo = 1 
cgi.rfc2616_headers = 1

#windows 启动PHP用 php-cgi.exe -b 127.0.0.1:9000 -c php.ini 



#nginx.conf配置文件中也有示例,打开#后做修改
location ~ \.php$ {
	#root  			html;    		#可改目录,windows以/分隔, 同location / {root  xx的值,也可不改}
    fastcgi_pass  localhost:9000;  #php-fpm 的listen
	#这可以是 unix:/run/xxx-php-fpm.sock;  对应php-fpm 配置的listen=/run/xx-php-fpm.sock(文件必须在/run下,php-fpm会自动创建) 还有其它配置l isten.owner=nginx listen.group=nginx listen.allowed_clients=127.0.0.1 
	#socket的限制,只能本机通信,不能和外网通信

    
	fastcgi_index  index.php;
 	fastcgi_param  SCRIPT_FILENAME $document_root$fastcgi_script_name;   # 原/scripts为修改 $document_root 即root的值
	
	include        fastcgi_params;
}

启动nginx用 nginx.exe -p D:\Program\nginx-1.16.1
-p(prefix)

--phpinfo.php文件放html目录
<?php
phpinfo();
?>

测试成功

------Nginx PHP 的php-fpm方式 (linux)
源码编译PHP 加选项 --enable-fastcgi --enable-fpm (为nginx用的 )
FPM=fastcgi process manager 有配置文件php-fpm.conf 
	有配置listen_address,allowed_clients 
php-fpm 选项
	 --php-ini path|file
    -c 指定查找php.ini文件位置


php7目录(php-fpm.conf 没有指定php.ini?? 编译php-fpm时指定的默认值??)
/etc/php7/cli/php.ini  里没有配置 extension_dir??,也没有配置conf.d??
/etc/php7/conf.d/
/usr/lib64/php7/extensions/


yum install php7-fpm 		 
yum install php7-devel (XDebug)
zypper install php7-xdebug
	/etc/php7/conf.d/xdebug.ini	
		xdebug.remote_port = 9000 必须要修改,和FPM端口相同
	/usr/lib64/php7/extensions/xdebug.so
	
	
cp /etc/php7/fpm/php-fpm.conf.default /etc/php7/fpm/php-fpm.conf   里有[global]
cp -n /etc/php7/fpm/php-fpm.d/www.conf{.default,}  #-n表示不覆盖已经存在的文件
#结果是 cp /etc/php7/fpm/php-fpm.d/www.conf.default  /etc/php7/fpm/php-fpm.d/www.conf 

 /etc/php7/fpm/php-fpm.d/www.conf  里[www]区默认有 listen = 127.0.0.1:9000 ,www是池名,可用 $pool 来取到值

systemctl restart  nginx php-fpm

如何同一nginx端口配置多个PHP上下文?????(多个location用alias)


-------------PHP 用Apache
源码编译PHP

./configure --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-apxs2=/usr/local/apache2/bin/apxs 
(路径不要以/ 结尾,　可--with-config-file-path=/etc/php.ini 所在的路径 PREFIX/lib)

cp php.ini-dist  /usr/local/php5/lib/
 
要libxml2 


make
make test
make install 

##make install 后在/usr/local/apache2/modules/libphp5.so 就有了
##httpd.conf 中也有了LoadModule php5_module        modules/libphp5.so

AddType application/x-httpd-php  .php 放在最外面

 
cp php.ini-dist /usr/local/lib/php.ini

httpd.conf文件中要有
AddType application/x-httpd-php  .php  .phtml
#AddType application/x-httpd-php-source .phps  高亮
LoadModule php5_module libexec/libphp5.so


#启用apache模块 php
a2enmod php7 因为安装的是apache2-mod_php7 (文档上说zabbix-3不支持php7,测试最后可以使用frontend)

#启用ZABBIX标志，为/etc/apache2/conf.d/zabbix.conf文件使用
a2enflag ZABBIX 

#启用POSTFIXADMIN标志，为/etc/apache2/conf.d/postfixadmin.conf文件使用
a2enflag POSTFIXADMIN 

vi /etc/php7/apache2/php.ini进行修改 
-------------


================OpenResty
由中国人发起
基于nginx,使用lua 语言

源码安装

cd openresty-1.15.8.1

 ./configure -j2
 提示 you need to have ldconfig in your PATH env when enabling luajit. 可以使用yast安装luajit
ldconfig在/sbin/下，PATH中没有  export PATH=$PATH:/sbin
报 ./configure: error: the HTTP rewrite module requires the PCRE library (yast可安装，pcre2-devel不行, pcre-devel可以的)
报 ./configure: error: SSL modules require the OpenSSL library. (yast可安装 libopenssl-1_1-devel)
gmake
gmake install

export PATH=/usr/local/openresty/bin:$PATH
export PATH=/usr/local/openresty/nginx/sbin:$PATH

resty -e 'print("hello, world")'

mkdir openResty_Data
cd  openResty_Data
mkdir logs/ conf/

--vi conf/nginx.conf
worker_processes  1;
error_log logs/error.log;
events {
    worker_connections 1024;
}
http {
    server {
        listen 8080;
        location / {
            default_type text/html;
			#这里做了增强
            content_by_lua_block {
                ngx.say("<p>hello, world</p>")
            }
        }
    }
}

nginx -p `pwd`/ -c conf/nginx.conf



================Kong
基于openResty
API网关   将安全认证，流量控制，审计日志，黑白名单等实现

有docker ， kubernate 版本，
没有windows版本

源码安装依赖于  OpenResty 1.13.6.2  依赖openssl.h

依赖于luarocks  (可以yast安装)
依赖于 lua.h,
		安装lua53-devel-5.3.4 依赖于
				lua-macros-20170611-lp151.2.70.noarch.rpm
		安装后lua.h在/usr/include/lua5.3/目录
	gcc提示要求5.3版本 
	不能源码安装lua(除非修改PREFIX), 因为找 /usr/include/lua5.3
	cd lua-5.3.0  
	make linux   依赖 <readline/readline.h> yast可安装 readline-devel (即最新的7版本)
	sudo make install INSTALL_TOP=/usr
	sudo make uninstall

方式一
luarocks install kong 1.2.1-0   #Lua 包管理工具Luarocks,类似 maven,npm

luarocks 的默认下载地址是 https://luarocks.org 
可用下面2个镜像
http://luafr.org/moonrocks/
http://luarocks.logiceditor.com/rocks

luarocks --server=http://luafr.org/moonrocks/ install kong 1.2.1-0  
Warning提示安装 luasec 支持https

后面报  (和openResty没关系)
bit.c:79:2: error: #error "Unknown number type, check LUA_NUMBER_* in luaconf.h"
 #error "Unknown number type, check LUA_NUMBER_* in luaconf.h"


方式二 
https://github.com/kong/kong 下载源码zip  目前版本 kong-1.2.1
cd kong
sudo make install
	 也是下载 https://luarocks.org/luabitop-1.0.1-1.src.rock 形式安装，还不能指定server
    也是一样报  bit.c:79:2: error: #error "Unknown number type, check LUA_NUMBER_* in luaconf.h"
 #error "Unknown number type, check LUA_NUMBER_* in luaconf.h"
		
		可能是luabitop-1.0.1-1.src.rock 代码问题, 用lua53-devel-5.3.4不行，源码安装lua-5.3.0  也不行
	
目前openSUSE下没办法了，用docker版本吧

----kong centOS
cd /etc/yum.repos.d/
vi kong.repo 写入
[kong]
name=kong
baseurl=https://kong.bintray.com/kong-rpm/centos/7
gpgcheck=0
keepcache=1 
 
 
sudo yum install kong 最新版本是不稳定
sudo yum install kong-1.2.0
ls /var/cache/yum/x86_64/7/kong/packages/
有保留 kong-1.2.0.el7.noarch.rpm

postgreSQL

CREATE USER kong;
ALTER USER kong WITH password 'kong';
CREATE DATABASE kong OWNER kong;

kong migrations bootstrap [-c /path/to/kong.conf]

kong start [-c /path/to/kong.conf]

curl -i http://localhost:8001/

本机仿问外网IP就不行了
/etc/kong/kong.conf.default 有配置 admin_listen=127.0.0.1:8001

kong config init 当前目录生成kong.yml

检查配置文件语法
kong check  ./kong.yml

cp /etc/kong/kong.conf.default /etc/kong/kong.conf
admin_listen=127.0.0.1:8001 修改为 0.0.0.0：8001
#admin_error_log=logs/error.log #rpm安装包是/usr/local/logs/error.log


kong check  /etc/kong/kong.conf
kong stop
kong start -c /etc/kong/kong.conf

警告 "ulimit -n" 至少 "4096" 
vi /etc/systemd/system.conf 
DefaultLimitNOFILE=4096


也支持限流功能(nginx也支持)

Router 转到 Service,一个Service可以有很多的Router

resetful admin API 在端口 8001




konga 配置Service，输入Name值example-service，Url值http://mockbin.org (代理的服务根URL) 效果同下 Admin API
curl -i -X POST \
  --url http://localhost:8001/services/ \
  --data 'name=example-service' \
  --data 'url=http://mockbin.org'
  
  
konga 在建立的Service中建立Router，Host中输入主机名example.com ,Protocals中输入http,https ？？,Methods 中输入get？？？，paths中输入/my-path???
curl -i -X POST \
  --url http://localhost:8001/services/example-service/routes \
  --data 'hosts[]=example.com'

默认使用8000端口做代理
curl -i -X GET \
  --url http://localhost:8000/ \
  --header 'Host: example.com'
  
启用 key-auth 插件，konga 的key names默认值为apikey，放在头中或者参数都可
curl -i -X POST \
  --url http://localhost:8001/services/example-service/plugins/ \
  --data 'name=key-auth'
  


konga建立Consumers 
 curl -i -X POST \
  --url http://localhost:8001/consumers/ \
  --data "username=Jason"
  
为已有的consumer 建立key，konga中Consumers->选中->Credentials-> API KEYS-> 按钮+CREATE API KEY
curl -i -X POST \
  --url http://localhost:8001/consumers/Jason/key-auth/ \
  --data 'key=ENTER_KEY_HERE'

带key请求
curl -i -X GET \
  --url http://localhost:8000 \
  --header "Host: example.com" \
  --header "apikey: ENTER_KEY_HERE"
  
---配置文件 kong.conf
log_level = debug  可被环境变量  export KONG_LOG_LEVEL=error 覆盖

nginx_http_ 开头 注入 nginx的http块
nginx_proxy_ 开头 和 nginx_admin_ 开头的 注入 nginx的 server块,对应kong的proxy端口,admin端口

prefix=/usr/local/kong 可以通过kong start -p 来覆盖

---plugin 
可是全局插件 ,Service级插件，Consumer级插件,Rout级插件

限流插件在Service上启用
curl -X POST http://127.0.0.1:8001/services/example-service/plugins \
    --data "name=rate-limiting"  \
    --data "config.second=5" \
    --data "config.hour=10000"
    
IP限制插件    
  curl -X POST http://127.0.0.1:8001/services/example-service/plugins \
    --data "name=ip-restriction"  \
    --data "config.whitelist=192.168.0.1" \
    --data "config.whitelist=192.168.1.0/24"

还有oauth2插件，cors跨域插件,Session插件， Proxy Caching插件,http log插件
Request Termination熔断，zipkin插件

upstream同nginx的，做分流

    
---kong cluster
 

  
--------kong-dashboard web界面工具 linux版本 

https://www.npmjs.com/package/kong-dashboard  兼容版本
 
npm install -g kong-dashboard
版本是 kong-dashboard@3.6.0    可兼容kong >= 0.9, <2.0.0

kong-dashboard start --kong-url http://127.0.0.1:8001
   --port [port] 
   --basic-auth user1=password1 user2=password2

访问
http://localhost:8080

--------konga web界面工具 linux版本,比kong-dashboard功能更多
 使用anjular
 kong admin 0.14.3
https://github.com/pantsel/konga/blob/master/README.md#compatibility 兼容版本 只说了 0.14.0 版本以前
 
 
git clone https://github.com/pantsel/konga.git
cd konga
npm i


开发模式启动
npm start
http://localhost:1337
第一次进入 http://localhost:1337/register 注册Admin用户,如返回错误的json，必须重新注册，如密码简单
配置kong的Admin URL



生产模式启动
#postgresql
#CREATE DATABASE konga OWNER kong;

初始化
node ./bin/konga.js  prepare --adapter postgres --uri postgresql://localhost:5432/konga

配置
cp .env_example  .env

运行
npm run production



----kong docker安装
docker network create kong-net

使用PostgreSQL,启动
docker run -d --name kong-database \
               --network=kong-net \
               -p 5432:5432 \
               -e "POSTGRES_USER=kong" \
               -e "POSTGRES_DB=kong" \
               postgres:9.6
 建立后启动
docker container start kong-database

准备数据库
docker run --rm \
     --network=kong-net \
     -e "KONG_DATABASE=postgres" \
     -e "KONG_PG_HOST=kong-database" \
     -e "KONG_CASSANDRA_CONTACT_POINTS=kong-database" \
     kong:latest kong migrations bootstrap
	 
启动kong ，KONG_DATABASE指定用哪种数据库,这里用 postgres

docker run -d --name kong \
     --network=kong-net \
     -e "KONG_DATABASE=postgres" \
     -e "KONG_PG_HOST=localhost" \
     -e "KONG_CASSANDRA_CONTACT_POINTS=kong-database" \
     -e "KONG_PROXY_ACCESS_LOG=/dev/stdout" \
     -e "KONG_ADMIN_ACCESS_LOG=/dev/stdout" \
     -e "KONG_PROXY_ERROR_LOG=/dev/stderr" \
     -e "KONG_ADMIN_ERROR_LOG=/dev/stderr" \
     -e "KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl" \
     -p 8000:8000 \
     -p 8443:8443 \
     -p 8001:8001 \
     -p 8444:8444 \
     kong:latest
	 
下次启动
dockerd
docker container start kong


测试有返回json
curl -i http://localhost:8001/
查versio是1.1.2



docker volume create kong-vol
docker volume inspect kong-vol  看MountPoint目录


--------kong-dashboard docker版本
https://github.com/PGBI/kong-dashboard
 

docker run --rm -p 8080:8080 pgbi/kong-dashboard start --kong-url http://127.0.0.1:8001

报连接不上???
 
浏览器打开 http://localhost:8080

================Ceph
openStack 使用这个火的
不适合存小文件 

kubernetes 的存储要求支持restful接口，有块存储接口

Suse 有单独的支持  有对象存储和块存储功能 
Ceph File System 分布式文件系统  类似的还有 GlusterFS


有使用leveldb (google实现的非常高效的kv数据库)
http://docs.ceph.org.cn/start/  中文的有点老,和新英文有不同,要注意
https://ceph.io/get/
https://github.com/ceph/ceph
 

--- 源码编译安装
ceph_14.2.4.orig.tar.gz

./install-deps.sh
	 里面就是执行了 zypper  install systemd-rpm-macros  安装了很多的python3的包
./do_cmake.sh
cd build
make 		开始长时间不动,后面是C编译 时间也很长，到5%花了约20分钟放弃，第二次到11%也花了20分钟左右
sudo make install
----

---openSUSE-leap-15.1  安装
yast安装中有 ceph-14.2.0 版本(http://download.opensuse.org/distribution/leap/15.1/repo/oss/)
zypper search -v ceph
 

https://en.opensuse.org/openSUSE:Ceph
zypper ar https://download.opensuse.org/repositories/filesystems:/ceph/openSUSE_Leap_15.1/filesystems:ceph.repo
ar=addrepo 生成文件 /etc/zypp/repos.d/filesystems_ceph.repo 里面是ceph-15 (octopus 章鱼)版本,修改 keeppackages=1
zypper install ceph-deploy 版本是 1.5.39
zypper install ceph-radosgw 选择1 升级已有的,安装新的


--------CentOS/RHEL 7 安装  
--安装信任的KYES,避免安全警告
sudo rpm --import 'https://download.ceph.com/keys/release.asc'

--安装  CEPH DEPLOY
epel仓库 sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm  可能已经安装了

https://download.ceph.com/rpm-* 找更新日期最新   Nautilus (14.2.z)  (鹦鹉螺)
即baseurl为  https://download.ceph.com/rpm-nautilus/el7/noarch

中国镜像为 http://mirrors.ustc.edu.cn/ceph/
--vi /etc/yum.repos.d/ceph.repo  (ceph-release包就中有这个文件,但里面版本有点老)
[ceph]
name=Ceph packages for $basearch
#baseurl=https://download.ceph.com/rpm-{ceph-release}/{distro}/$basearch
#baseurl=https://download.ceph.com/rpm-nautilus/el7/$basearch
baseurl=http://mirrors.ustc.edu.cn/ceph/rpm-nautilus/el7/$basearch
enabled=1
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc

[ceph-noarch]
name=Ceph noarch packages
#baseurl=https://download.ceph.com/rpm-{ceph-release}/{distro}/noarch
#baseurl=https://download.ceph.com/rpm-nautilus/el7/noarch
baseurl=http://mirrors.ustc.edu.cn/ceph/rpm-nautilus/el7/noarch
enabled=1
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc

[ceph-source]
name=Ceph source packages
#baseurl=https://download.ceph.com/rpm-{ceph-release}/{distro}/SRPMS
baseurl=http://mirrors.ustc.edu.cn/ceph/rpm-nautilus/el7/SRPMS
enabled=0
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc

---
# yum update #更新系统
yum install ceph-deploy  安装2.0.1
yum install ceph  安装14.2.5  
yum install ceph-radosgw ( Rados REST gateway)
yum install yum-plugin-priorities ceph-release
 
依赖很多python，源码中有CPP代码
DVD带的
rpm -ivh python-mako-0.8.1-2.el7.noarch.rpm pyOpenSSL-0.13.1-4.el7.x86_64.rpm python-markupsafe-0.11-10.el7.x86_64.rpm librabbitmq-0.8.0-2.el7.x86_64.rpm python-beaker-1.5.4-10.el7.noarch.rpm python-tempita-0.5.1-6.el7.noarch.rpm python-paste-1.7.5.1-9.20111221hg1498.el7.noarch.rpm
还有34个包
---preflight 准备
同步时间
yum install ntp ntpdate ntp-doc  (/etc/ntp.conf)

每个节点建立新用户,如ceph01
无密码使用 sudo命令
echo "ceph01 ALL = (root) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/ceph01
sudo chmod 0440 /etc/sudoers.d/ceph01
使用ssh-keygen,ssh-copy-id 配置admin节点(使用ceph-deploy命令)到ceph节点 无密码登录(root用户)

打开防火墙
firewall-cmd --zone=public --add-service=ceph-mon --permanent
firewall-cmd --zone=public --add-service=ceph --permanent
firewall-cmd --reload

只centOS有的
setenforce 0
yum install yum-plugin-priorities
----如重新安装清历史
ceph-deploy purge node1 node2 node3  #会删安装包,做好备份
ceph-deploy purgedata node1 node2 node3   
ceph-deploy forgetkeys
rm ceph.*
--
mkdir ceph-dir && cd ceph-dir
ceph-deploy new node1  (root用户执行)初始化监控节点,在当前目录下生成ceph.conf  , ceph.mon.keyring

--修改ceph.conf 在[global]下增加
public network = <本机IP>/24  #如果多于一个网卡,这个是为客户端使用,cluster network
#ms bind ipv6 = true #如果使用IPV6 
osd pool default size = 3  #默认是3,如只有两节点修改为2

ceph-deploy install --release nautilus node1 node2 node3 (root用户执行)会所指定的ceph节点 安装preflight要的和ceph
	(如报版本错误是因/etc/yum.repos.d/ceph.repo里的东西老,测试过只两个节点可运行一些命令)

ceph-deploy mon create-initial  (root用户执行)如在openSUSE上失败??? 可能是版本不一致,在 centOS7上成功 ,当前目录下生成了很多xx.keyring文件
	 (覆盖/etc/ceph/ceph.conf 加 --overwrite-conf  即 ceph-deploy  --overwrite-conf mon create-initial)
ceph-deploy admin node1 node2 node3
ceph-deploy mgr create node1

每个节点有一个未使用的磁盘/dev/vdb (虚拟磁盘行不行??? ) 
ceph-deploy osd create --data /dev/vdb node1  
(日志有 ceph-volume --cluster ceph lvm create --bluestore --data /dev/sdb  有使用vgcreate命令做的,即LVM2来做的,做过的提示volume '/dev/sdb' is already in volume group 要用vgremove)
ceph-deploy osd create --data /dev/vdb node2
ceph-deploy osd create --data /dev/vdb node3

ceph-deploy osd list node1 其实是运行 ceph-volume lvm list



ceph health (要root执行)(如两个节点 报HEALTH_WARN OSD count 2 < osd_pool_default_size )
#systemctl list-unit-files | grep ceph
	ceph-mds.target  
	ceph-mgr.target
	ceph-mon.target
	ceph-osd.target
	ceph-radosgw.target
	ceph.target

停止
systemctl disable ceph.target 

systemctl disable ceph-mds.target   
systemctl disable ceph-mgr.target
systemctl disable ceph-mon.target
systemctl disable ceph-osd.target
systemctl disable ceph-radosgw.target
 
systemctl disable  ceph-crash.service
systemctl disable  rbdmap.service


#ceph-deploy mon add node2 node3 #增加监控节点
ceph quorum_status --format json-pretty

#ceph-deploy mgr create node2 node3 #增加管理节点
ceph -s


#如使用Ceph Object Gateway(RGW) 默认监听 7480端口
可修改监听端口  ceph.conf 
[client]
rgw frontends = civetweb port=80

#ceph-deploy rgw create node1  #如何才能监听???

  
/var/lib/ceph/osd/ceph-0 存数据
/var/log/ceph/ceph.log 存日志 

ceph osd pool create mypool 128    #归置组(placement-groups=PG)总数128 ,http://docs.ceph.org.cn/rados/operations/placement-groups/
ceph osd lspools

echo "Test-data"> testfile.txt
rados put test-object-1 testfile.txt --pool=mypool
rados -p mypool ls
ceph osd map mypool test-object-1
rados rm test-object-1 --pool=mypool
ceph osd pool rm mypool #会删池下的所有对象 命令变的严格  
ceph osd pool rm mypool mypool --yes-i-really-really-mean-it  还要设置 mon_allow_pool_delete 为true

--块
http://docs.ceph.org.cn/rbd/rados-rbd-cmds/

rados block device (RBD)
 
rbd create --size 1024 mypool/bar   #--size单位是MB
rbd ls mypool
rbd info mypool/bar #有id的值

rbd resize --size 2048 mypool/bar (扩大)
rbd resize --size 1024 mypool/bar --allow-shrink (缩小)
rbd rm mypool/bar
rbd trash mv mypool/bar  放在回收站
rbd trash rm mypool/{image-id} 从回收站删除
rbd trash restore mypool/{image-id} --image new-name 从回收站恢复

---块map成fs
rbd create --size 1024 mypool/bar1   --image-feature layering  (rbd info mypool/bar有显示features)
#rbd help create 看有 --image-format 2 ,rbd info mypool/bar1 也有显示 format: 2

rbd map bar1 --pool mypool  --id admin   ##admin是最高权限  ceph auth list 看所有权限 
rbd map mypool/bar1 --id admin --keyring ./ceph.client.admin.keyring  
export CEPH_ARGS=--keyring=./ceph.client.admin.keyring 就不用第次加--keyring参数了(root用户默认有)

rbd showmapped 显示有 /dev/rbd0
rbd unmap /dev/rbd/{pool_name}/{image_name}
rbd unmap /dev/rbd0  #可多次map数字会变

mkfs.ext4 -q /dev/rbd0  (-q Quiet)
mount /dev/rbd0 /mnt/   
#开机自动挂载配置/etc/fstab文件
#/dev/rbd/foopool/bar1 /mnt/bar1 xfs noauto 0 0
/dev/rbd/mypool/bar1 /mnt/bar1 xfs noauto 0 0  #不推荐使用/dev/rbd0的方式,因再次map就会变为rbd1,要用noauto,不能用default

自动map要
vi /etc/ceph/rbdmap
#poolname/imagename id=client,keyring=/etc/ceph/ceph.client.keyring
mypool/bar1     id=admin,keyring=/home/dell/ceph-dir/ceph.client.admin.keyring
开机自启服务
systemctl enable rbdmap.service

块扩容
rbd resize --size 2048 mypool/bar1  后,df -h 还是原来的大小
要用 resize2fs /dev/rbd0   (e2fsprogs软件包中的)

---快照
#rbd snap create {pool-name}/{image-name}@{snap-name}  #一个镜像可以多次建立
rbd snap create mypool/bar1@bar1_bak01

#rbd snap ls {pool-name}/{image-name}
rbd snap ls mypool/bar1

#rbd snap rollback {pool-name}/{image-name}@{snap-name}
rbd snap rollback mypool/bar1@bar1_bak01  #回滚到之前的备份,看效果要重新mount,不能扩缩容(e2fsck -f /dev/rbd0)

#rbd snap rm {pool-name}/{image-name}@{snap-name}
rbd snap rm mypool/bar1@bar1_bak01 

rbd snap purge {pool-name}/{image-name}  #purge是删除所有快照
保护快照不可删除,才可以做克隆(新的镜像可读写)
#rbd snap protect {pool-name}/{image-name}@{snapshot-name}
rbd snap protect mypool/bar1@bar1_bak01 

#rbd clone {pool-name}/{parent-image}@{snap-name} {pool-name}/{child-image-name}
rbd clone mypool/bar1@bar1_bak01  mypool/bar1_2


#rbd snap unprotect {pool-name}/{image-name}@{snapshot-name}
rbd snap unprotect mypool/bar1@bar1_bak01 

#谁克隆了我,我的孩子是谁
#rbd children {pool-name}/{image-name}@{snapshot-name}
rbd children mypool/bar1@bar1_bak01

如要删除快照 必须要压平子镜像
#rbd flatten {pool-name}/{image-name}
rbd flatten rbd/new-image



ceph osd tree  显示哪个主机上有哪些osd及状态up/down
#blockdev --getsize64 /dev/rbd0

ceph-deploy disk list <hostname>

ceph-deploy create 可以拆成ceph-deploy prepare和active两步
ceph mon_status --format json-pretty  可用-f



systemctl status ceph-osd@12      # check status of osd.12
systemctl status ceph\*.service 

systemctl start ceph-osd@{id}
systemctl start ceph-mon@{hostname}
systemctl start ceph-mds@{hostname}

ceph-deploy disk zap <hostname> /dev/vd0  删除分区,增加osd时用
--- 移除osd.0
systemctl stop ceph-osd@0 
rm -rf /var/lib/ceph/osd/ceph-0/*
从crush map中移除
ceph osd crush remove osd.0
后ceph osd tree再看osd.0已经不在root组下了

ceph auth list
ceph auth del osd.0 

ceph osd tree 
ceph osd rm osd.0  后再查ceph osd tree 就没了
#umount /dev/xxxx  (是df -h看哪个挂在/var/lib/ceph/osd/ceph-0/,测试下来是tmpfs)

---增加mon
除了用ceph-deploy mon add 

也可用ceph-deploy mon create 

当前目录下的 ceph.conf文件中 mon_initial_members 和 mon_host 配置做修改

当前目录下的ceph.conf 做更新
ceph-deploy --overwrite-conf config push <hostname>  #把当前目录的推向所有节点,即/etc/ceph目录下

ceph-deploy mon create <hostname>

---删除mon
ceph-deploy mon destroy <hostname> 
ceph -s 和  ceph quorum_status --format json-pretty 都可看

---crush

ceph osd dump
ceph osd crush rule dump #通过crush rule可以把多个pool的数据分隔开 

rack  行李架； 支架 (服务器机架)
ceph osd tree 或 ceph osd crush tree 
默认就是 root->host->osd的层级, 可以有root->datacenter->room->rack->host

ceph osd getcrushmap -o crushmap.bin 是二进制文件 
crushtool  -d crushmap.bin -o crushmap.txt 反编译成文本
做修改后再编译
crushtool  -c crushmap.txt -o crushmap_2.bin  
应用编译的
ceph osd setcrushmap -i crushmap_2.bin  

ceph osd crush rule ls
ceph osd pool get {pool-name} crush_rule
把rule应用到pool上
ceph osd pool set <pool-name> crush_rule <rule-name>

增加bucket,{bucket-type} 一定要是 反编译文本中 存在的type,如room
ceph osd crush add-bucket {bucket-name} {bucket-type}
ceph osd crush add-bucket bucket01 room
ceph osd tree 就有了

移动bucket到指定的下面
ceph osd crush move {bucket-name} {bucket-type}={bucket-name}, [...]
ceph osd crush move  bucket01 root=default

删除bucket
ceph osd crush remove {bucket-name}
ceph osd crush remove bucket01

增加OSD
ceph osd create 建立一个空的OSD
ceph osd tree 看是 osd.2
ceph osd crush add osd.2 1 root=default host=rhel7  #放 root=default 下的 host=rhel7 下,权重是1

移动
ceph osd crush create-or-move osd.2 1 root=default 
删除osd
ceph osd crush remove osd.2 

--监控
ceph -w 一直看
ceph df 
ceph df detail
ceph status = ceph -s
ceph mon stat
ceph mon dump

ceph osd dump 有显示池的复本数
ceph pg dump 
web监控工具 Ceph 官方的 Kraken,Calamari

---性能测试工具 rados -p mypool bench ,Fio,

---网关 对象存储 未试
systemctl restart ceph-radosgw.service

ceph-authtool  --create-keyring  /etc/ceph/ceph.client.radosgw.`hostname`.keyring
ceph-authtool  --gen-key  --name  
---
坑!!!!
执行所有ceph命令都卡住不动了,包括ceph health , ceph -s ,ceph osd stat,ceph osd tree,没有错误??? 什么原因??? 日志在哪????
发现原因为另一个节点IP地址变化ping不通,purgedata时发现的,修改IP还是不行,可能是少一个节点

---cephadm 用来启动一个ceph cluster 
 yum install -y cephadm    没有??
 zypper install -y cephadm 

---- 


CephFS 是在Ceph’s distributed object store, RADOS之上的
Reliable Autonomic Distributed Object Store (RADOS)

ceph-deploy工具在admin节点的一个目录下生成很多文件 

一个 Ceph Storage Cluster 需要至少一个 
 	  Monitor		 当做冗余和HA至少3个节点
 	  Manager		  当做冗余和HA至少2个节点
 	  OSD (Object Storage Daemon)  当做冗余和HA至少3个节点
     Metadata Server(MDS) 也是需要的，当运行 Ceph File System 客户端.
 
  		如使用对象存储要  radosgw (aws的s3,openstack的swift)
  
一个文件切分成多个Object(默认按4MB分)  -> PG(重复OSD的为一组,Acting set中的第一位是组长)->OSD(台机器)

(一个Ojbect只会存在一个PG中,但一个PG中可能存一个文件中的多个Object,PG和OSD是多对多的关系)

Pool(LVM中的vg ,里面分多个image)  -> PG(LVM中的lv) -> OSD(LVM中的pv)

pool_id和ojbect_id做hash找对应的pg
PG映射为OSD使用Crush算法(CrushMap)

客户端连接monitor节点(高可用奇数个节点,用paxos算法,epoch版本号),可以有多个Monitor,主计算出cluster map,
	cluster map里面有monitor map,osd map,pg map,crush map,MDS Map
OSD每两秒汇报自己给monitor,同时监控组内的其它成员



----

ceph-daemon bootstrap --mon-ip *<mon-ip>* --output-config ceph.conf --output-keyring ceph.keyring --output-pub-ssh-key ceph.pub

ceph-daemon bootstrap --mon-ip 192.168.1.104 --output-config ceph.conf --output-keyring ceph.keyring --output-pub-ssh-key ceph.pub  
	Pulling latest ceph/daemon-base:latest-master-devel container. 日志显示在拉文件（镜像）
	Waiting for mon to start...  这里一直不动的

 

ceph volume create my-ceph

挂载使用
mount.ceph node1:6789:/ ~/client_cephfs_mnt/ -o name=admin,secretfile=~/admin.keyring
 

================GlusterFS
适合大文件,无元数据服务器

http://download.opensuse.org/repositories/home:/glusterfs:/Leap15.1-7/openSUSE_Leap_15.1/
zypper install glusterfs  是7.1版本

https://download.gluster.org/pub/gluster/glusterfs/LATEST/RHEL/  只有8.0和8.1 没有RHEL 7版本


================linux NIS  类似   Windows  domain 
要有下面的rpm包
yp-tools： 提供NIS相关查寻指令
ypbind ：提供Client的设置
ypserv ： 提供server的设置
portmap ：RPC所需要的信息
 

　
cat /etc/fstab 根目录　就是xfs　类型的
================OpenLDAP
http://www.openldap.org/
支持 LDAPv3
版本2.4.49 在2020/01更新

ldap客户端工具 Softerra LDAP Administrator 收费的只有windows版本
phpLDAPadmin (最近是2012更新)
JXplorer 免费(2016年更新),有商业版本,Java跨平台(windows/linux/osx),版本3.3.1.2要求osx10.6/10.7,普通用户安装
LDAP Browser  免费的只有windows版本


zypper install openldap2 安装是 openldap2-2.4.46-lp151.9.4.x86_64.rpm

默认监听的端口是389



================389 Directory Server (LADP 服务)
https://directory.fedoraproject.org/      fedora项目 
https://access.redhat.com/documentation/en-us/Red_Hat_Directory_Server/11/
支持 LDAPv3
最新版本 1.4.3.3

zypper install 389-ds (ds 1.4.x,OpenSUSE LEAP 有依赖perl组件 )
CentOS 8.1 (ds 1.4.x, 有cockpit界面)  使用 yum install/update epel-release 再 yum module install 389-directory-server:stable/default
CentOS 7 (ds 1.3.x) 使用 yum install 389-ds-base 再 setup-ds.pl,也可安装一些工具 389-admin 389-ds-console 389-admin-console 使用 setup-ds-admin.pl

windows版本有 389-Console-1.1.18-x86_64.msi(要java命令) 和 389-PassSync-1.1.7-x86_64.msi





================openVPN
https://openvpn.net/ 被中国墙了
https://github.com/OpenVPN/openvpn

openSUSE-leap-15.1 系统自带 openvpn-2.4.3-lp151.4.3.x86_64


------------XFS
CentOS 7.6 默认就是xfs类型文件系统(ext4的下一代)
CentOS 7.6 默认也是LVM的，swap分区和/分区都是在LVM下的xfs分区. 但/boot分不是在LVM下的，只是xfs
可选择 Btrfs(随机寻道/读写 和 创建和删除大量文件 不如XFS性能好) ，是和 LVM 同级的

UFS Explorer 可以恢复 xfs格式的数据 (trail)
windows 下读XFS ， WinAllFS，Crossmeta

https://github.com/crossmeta/sgi
https://www.crossmeta.io/ 是提供开发的


mkfs.xfs
mkfs -t xfs 
mount -t xfs 

==========================配置管理
--------- Ansible 配置管理
 
被Redhat收购  没有界面,使用python开发

让我们自动化部署APP
自动化运维工具  实现批量系统配置，批量程序部署，批量运行命令

收费的UI Ansible Tower,
免费UI版Semaphore https://github.com/ansible-semaphore
 
使用SSH不需要agent代理 ,适合机不太多
类似的工具 Saltstack 使用python开发,要agent代理,被控制服务器要安装的软件,像vnc,如批量安装agent也比较麻烦,除非开始初始安装系统时有,有代理性能和功能强,适合主机多
	Puppet 使用ruby开发, 适合更大的环境
	
主控机,master, 堡垒机 都是一个意思

ansible-2.7.10-lp151.1.1.noarch.rpm
openSUSE-leap-15.1 DVD自带的依赖
 rpm -ivh ./x86_64/python3-bcrypt-3.1.4-lp151.3.1.x86_64.rpm ./x86_64/python3-MarkupSafe-1.0-lp151.2.5.x86_64.rpm ./x86_64/libsodium23-1.0.16-lp151.4.3.x86_64.rpm ./x86_64/python3-PyYAML-3.13-lp151.1.1.x86_64.rpm ./noarch/python3-pytz-2018.5-lp151.1.1.noarch.rpm ./noarch/python3-Babel-2.5.1-lp151.2.2.noarch.rpm ./noarch/python3-Jinja2-2.10.1-lp151.1.1.noarch.rpm
 
 --源码安装
  https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html  
	Tarballs of Tagged Releases  下载  ansible-2.9.2.tar.gz    包
	Latest Releases via Pip			使用 pip install --user ansible
	 
	https://github.com/ansible/ansible/releases
	
# yum install python36-setuptools #centOS
# easy_install pip
#pip3 install ansible
# https://github.com/ansible/ansible/tree/devel/examples/ansible.cfg
进入源码包
pip3 install ./requirements.txt
python setup.py  install

--

Control Node不支持windows系统
Managed Node  使用ssh,sftp

ansible --version 
 可显示配置文件路径   config file = /etc/ansible/ansible.cfg


vim /etc/ansible/hosts 添加被控制主机的IP地址列表

控制主机中生成ssh密钥对
ssh-keygen -t rsa
 
查找顺序
1  ANSIBLE_CONFIG 环境变量
2  ./ansible.cfg
3  ~/.ansible.cfg
4  /etc/ansible.cfg

ansible-config  dump 看目前的环境变量 

ansible localhost -c local -a "whoami"
  -c CONNECTION, --connection=CONNECTION
  -a MODULE_ARGS, --args=MODULE_ARGS   



/etc/ansible/hosts 文件中可写IP,也可写主机名
ansible <ip/hostname/group> -m ping  -k  
	-k, --ask-pass  提示输入对方机器密码
#主机名要是配置文件中有的,也可是组名,也可是all,不要即有ip又有对应的主机名,会重复执行
主机要事先ssh连接过有~/.ssh/known_hosts记录,可指定多个主机,但可能每个机器root密码不一样,要使用ssh-keygen方式,所有节点做一次 ssh-copy-id <ip>

---ansible.cfg
#host_key_checking = False 放开就可以不用被控主机事先连接过

#inventory      = /etc/ansible/hosts
#log_path = /var/log/ansible.log  默认没有日志文件,打开才有
#module_name = command 默认模块名,当没-m参数时
---
ansible-doc -l 列出可用模块 ,有2千多个
ansible-doc -l  | grep win
ansible-doc -a 所有模块文档,不常用
ansible-doc ping 
ansible-doc -s ping   简单显示 --snippet 

ansible all --list-hosts 显示解析后主机,调试比较有用

ansible all -u root -a "whoami"  -k  指定连接用户,默认当前系统用户
ansible all -u dell  -a "ls /root"  -k  -b -K # -b 即sudo功能,配置文件中有sudo_user=root项 -K sudo时的口令

如多个主机都执行用:分隔(或的关系)
如多个主机只要重叠的用:&(并且的关系),要用引号包起来如'all:&rhel7'
						:!(非的关系) 如'all:!rhel7'
	还支持正则表达式

执行过程是根据模块名生成临时.py在~/.ansible/tmp目录下,是配置的#local_tmp = ~/.ansible/tmp,复制到远程主机的相同目录也是配置的,加执行权限,再执行,再删除
可用 -vvv 看执行过程,里有 put,chmod,rm命令

ansible-doc command
ansible all   -a "removes=/etc/fstab cat /etc/fstab"  #removes表示如文件不存在就不执行  
ansible all   -a "chdir=/boot ls"
ansible all   -a "chdir=/opt ./test.sh"  #脚本中开头要加 #!/bin/bash,必须先在远程有脚本
ansible all   -a "useradd user1"
ansible all   -a "getent passwd user1"  
ansible all   -a "getent passwd user1"  --limit rhel7 只对某一个主机执行
ansible all   -a "echo 456 |passwd --stdin user1"  #就不行了,只是打印出来,不支持 |  > <  $  ,只能放在shell中
ansible all   -a "echo $HOMENAME"
ansible all   -a 'echo $HOMENAME' #就不行了
ansible all -m shell  -a 'echo $HOMENAME'
ansible all  -m shell  -a "echo 456 |passwd --stdin user1"
ansible all  -m script -a "./test.sh"  #使用本地脚本,输出JSON结果,控制台显示在stdout_lines中

显示日志的颜色,绿色只查,黄色做了修改

ansible-doc copy
backup:如文件存在创建一个备份
content: 替代src:
dest: 
mode: 权限
owner:

ansible all  -m copy -a "src=/etc/selinux/config dest=/etc/selinux/config backup=yes"  做备份以时间结尾,如文件未修改不会生产备份

ansible all  -m shell -a "rm -f /etc/selinux/config.*"  #*只能用shell模块
ansible all  -m shell -a 'ls /etc/selinux/config.*'    #要用shell 必须单引号,双引号不行
ansible all  -m shell -a 'reboot'
ansible all  -m shell -a 'getenforce'

ansible-doc fetch 从被控机上取日志
ansible all  -m fetch -a 'src=/var/log/messages dest=/root validate_checksum=false '  
#原文件只支持文件,不支持目录 ,不支持通配符(可用shell模块打包),生成文件/root/<hostname>/var/log/messages
 

file,archive,unarchive,hostname,cron,yum,service,user,group模块


ansible-galax 从  https://galaxy.ansible.com/ 上下载role(是playbook的集合)
ansible-galax install xx 
 
ansible-galaxy install brianshumate.consul  下载到~/.ansible/roles/目录下,有 brianshumate.consul 目录 ,可复制出来一个新的
	tasks 目录有很多.yml文件

ansible-galaxy list 就是显示~/.ansible/roles/的文件夹
ansible-galaxy remove brianshumate.consul

vi showHostname.yml
---
- hosts: all
  remote_user: root
  tasks:
  - name: show hostname
    command: hostname


ansible-playbook showHostname.yml

ansible-valt 对yml文件做加密
ansible-vault encrypt showHostname.yml 提示输入密码,原来的文件变为二进制了(原明文件没有了)
ansible-vault decrypt showHostname.yml 
ansible-vault view showHostname.yml 
ansible-vault edit showHostname.yml 
ansible-vault rekey showHostname.yml   #修改密码
ansible-vault create new.yml #新建一个加密文件,提示输入新密码

ansible-console后有交互提示符(灰色的,不明显)
dell@all (3)[f:5]$       #(3)表示all主机里有3个,[f:5] 表示fork为5

dell@all (3)[f:5]$  cd rhel7  # rhel7 是主机名或组名

dell@rhel7 (3)[f:5]$ forks 3    

dell@rhel7 (3)[f:3]$   			# ?或help是模块名
dell@rhel7 (3)[f:3]$ command hostname

 
单条命令执行 (ansible xxx)叫adhoc 



vi batch-test.yml
---
- hosts: all
  remote_user: root
  tasks:
  - name: create new file
    file: name=/opt/newfile state=touch
  - name: create user  
    user: name=user2 
  - name: install nginx   
    yum: name=nginx state=installed
  - name: copy config file
    copy: src=/etc/nginx/conf.d/default.conf dest=/etc/nginx/conf.d/
    notify: restart service #对应handlers中的名字,修改了配置文件,再次执行时因服务已经启动,不会再次启动,使用notify,handler
    #notify 也可是一个数组
  - name: copy data file
    copy: src=/usr/share/nginx/html/index.html dest=/usr/share/nginx/html
  - name: start service
    service: name=nginx state=started enabled=yes
    ignore_errors: true  #如失败继续执行
    tags: tagStartService #后可单独执行某些标签,可以多个动作共用一个标签
  handlers:
    - name: restart service
      service: name=nginx state=restarted  
     
ansible-playbook  -C batch-test.yml  #  -C, --check  检查一次
ansible-playbook   batch-test.yml  --list-hosts
ansible-playbook   batch-test.yml  --list-tasks
ansible-playbook   batch-test.yml  --limit rhel7  #只对某一个主机执行
ansible-playbook   batch-test.yml   -t tagStartService 	 #执行指定标签,多个用逗号分隔
ansible-playbook   batch-test.yml  --list-tags


hostname模块其实是调用setup模块,有系统信息
ansible all -m setup | grep hostname 找到 ansible_hostname 
ansible all -m setup | grep fqdn 找到 ansible_fqdn
ansible all -m setup  -a 'filter=ansible_hostname'

ansible all -m setup  -a 'filter=*ip*'  显示有 ansible_all_ipv4_addresses



变量

vi batch-install.yml
---
- hosts: all
  remote_user: root
  tasks:
  - name: install {{ appName }}
    yum: name={{ appName }} state=installed
  - name: start {{ appName }} service
    service: name={{ appName }} state=started enabled=yes
  #vars_files: #变量存外部文件中
  #- vars.yml  
  vars: #文件中可定义变量  可覆盖主机中的变量
  - appName: redis 

ansible-playbook  -e 'appName=nginx' batch-install.yml  #多个变量有空格分隔 ,可以覆盖文件中同名变量
# ansible all -m shell -a 'yum -y remove redis nginx'  


如果想每个主机定义自己的变量 在 /etc/ansible/hosts文件中的  主机名 后加参数形式

/etc/ansible/hosts
[ip_hosts]
192.168.114.132  var_hostname=rhel7   #这里优级高于公共组 ip_hosts:vars 中的变量 

[ip_hosts:vars]
var_domain=example.org

vi batch-hostname.yml
---
- hosts: ip_hosts
  remote_user: root
  tasks:
  - name: set hostname {{ var_hostname }}.{{ var_domain }}
    hostname: name={{ var_hostname }}.{{var_domain}}  
 
ansible-playbook  batch-hostname.yml


也可以使用setup 模块中的变量  
 ansible all -m setup | grep fqdn 找到 ansible_fqdn
 ansible all -m setup | grep mem 找到 ansible_memtotal_mb ansible_memfree_mb

vi show-hostname.yml
---
- hosts: all
  remote_user: root
  tasks:
  - name: show hostname {{ ansible_fqdn }} 
    command: echo {{ ansible_fqdn }}  ##控制台信息显示不了
 
ansible-playbook  show-hostname.yml




模板使用jinja2语言  ,有template模块 只能用于playbook,  ansible-doc -s template
 

ansible all -m setup | grep cpu 找到 ansible_processor_vcpus

cp /etc/nginx/nginx.conf  templates/nginx.conf.j2
	worker_processes {{ansible_processor_vcpus + 1}};  #可以动态配置(auto)

	还可使用for,if,也可用.对象的形式
	{% for item in my_var_items %}	
		{% if  item.xx is defined %}	
		
		{% endif %}	
	{% endfor %}	
	
	
vi template-config.yml
---
- hosts: all
  remote_user: root
  #vars_files: #变量存外部文件中
  #- vars.yml  
  tasks:
  - name: template config file
    template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf #默认找当前目录下的templates目录中的文件
   
 
ansible-playbook  template-config.yml


ansible all -m setup | grep os_family 有 ansible_os_family 显示不准???  centOS 的值也为Redhat
ansible all -m setup -a 'filter=*distribution*'   有显示
	"ansible_distribution": "CentOS", 
	"ansible_distribution_major_version": "7",

可为Redhat和SUSE使用不同安装方式,when 测试不执行??? 双引号也不行,
vi os-diff.yml
---
- hosts: all
  remote_user: root 
  tasks: 
  - name: yum install nginx   
    yum: name=nginx state=installed
    #when: ansible_distribution == 'CentOS'
    when: ansible_distribution_major_version == '7'
  - name: zypper install nginx   
    zypper: name=ngix state=installed
    when: ansible_distribution == 'SUSE'

ansible-playbook  os-diff.yml

 
vi iterator.yml
---
- hosts: all
  tasks: 
  - name: create many files
    file: name=/tmp/{{ item }} state=touch #特殊变量item引用with_items中的项
    with_items:
      - one
      - two
      - three
  - name: create many users
    user: name={{ item.name }} group={{item.group}}	#对象属性使用.
    with_items:
      - {name: user1, group: nobody}
      - {name: user2, group: wheel}
      - {name: user3, group: wheel}

ansible-playbook   iterator.yml



role 是playbook的很多文件做分类, 有目录  /etc/ansible/roles 
roles/nginx/ 下的目录规则 tasks,template,files,vars,handlers 

main.yml 
- include: xx.yml  #include现在过时了(动态), 如是 import_playbook,import_tasks是静态
- include: yy.yml

entry.yml  
- hosts: all
  remote_user: root
  roles:  #hosts同级的, 2.3版本以后有 include_role(动态) , import_role
  - role: nginx   #在roles下的目录名
  #- {role: redis,tags:["cache","session"],when: xx == 2}  #可加对象标签






========================== 性能监控
---------Zabbix 性能监控 最常用的
发音   扎比克斯 开源

Zabbix proxy 可以代替 Zabbix server采集性能和可用性数据,通常Zabbix proxy和Zabbix server之前有防火墙
Zabbix proxy在Zabbix的部署是可选部分；但是proxy的部署可以很好的分担单个Zabbix server的负载。Zabbix proxy 需要使用独立的数据库
Zabbix agents 部署在被监控目标上，用于主动监控本地资源和应用程序，并将收集的数据发送给 Zabbix server。



官方最新是4.4版本,4.0是LTS版本，有SUSE Linux，CentOS版本，还有docker镜像版本
zabbix-4.0 可以支持MySQL8.0(yast 带 MariaDB 10.2) 

https://developer.aliyun.com/mirror 阿里云 镜像 有 zabbix
https://mirrors.aliyun.com/zabbix/

https://repo.zabbix.com/zabbix/4.4/sles/15/x86_64/zabbix-release-4.4-1.el15.noarch.rpm  可以安装在openSUSE-leap15.1上
 仓库地址为 http://repo.zabbix.com/zabbix/4.4/sles/15/x86_64/

https://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/zabbix-release-4.4-1.el7.noarch.rpm
 仓库地址为 http://repo.zabbix.com/zabbix/4.4/rhel/7/x86_64/

yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-nginx-conf zabbix-agent
zypper install zabbix-server-mysql zabbix-web-mysql zabbix-nginx-conf zabbix-agent
 


openSUSE-leap-15.1 DVD带的依赖
rpm -ivh  psqlODBC-10.01.0000-lp151.2.3.x86_64.rpm unixODBC-2.3.6-lp151.2.3.x86_64.rpm libssh2-1-1.8.0-lp151.5.1.x86_64.rpm libmariadb3-3.0.7-lp151.2.1.x86_64.rpm libpq5-10.6-lp151.1.4.x86_64.rpm libmariadb3-3.0.7-lp151.2.1.x86_64.rpm 


 从源码编译安装 zabbix-4.2
 ./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl 
 #--with-libxml2
 可选的 --enable-proxy --with-ssh2 
configure: error: LIBXML2 library not found  							(yast 安装 libxml2-devel)
configure: error: Not found Net-SNMP library								(yast 安装 net-snmp-devel)
configure: error: Unable to use libevent (libevent check failed)	(yast 安装 libevent-devel)
configure: error: Curl library not found  								(yast 安装 libcurl-devel)
configure: error: Unable to use libpcre (libpcre check failed)		(yast 没有 libpcre-devel????)
 
 
---MySQL

create database zabbix character set utf8 collate utf8_bin;
create user zabbix@localhost identified by 'zabbix';
grant all privileges on zabbix.* to zabbix@localhost ;
ALTER USER zabbix@localhost IDENTIFIED WITH mysql_native_password   BY 'zabbix';

create user zabbix@'%' identified by 'zabbix';
grant all privileges on zabbix.* to zabbix@'%' ;
ALTER USER zabbix@'%' IDENTIFIED WITH mysql_native_password   BY 'zabbix';

zcat /usr/share/doc/packages/zabbix-server-mysql/create.sql.gz | mysql -uzabbix -p zabbix
共建立了149张表

--- postgresql  
bin/createuser --pwprompt zabbix
bin/createdb -O zabbix -E Unicode -T template0 zabbix

-O, --owner
-E, --encoding
-T, --template=TEMPLATE      template database to copy

PostGreSQL开启远程登录
/opt/pgsql/./data/pg_hba.conf
#增加如下
host		 all			 all 					0.0.0.0/0				md5
/opt/pgsql/./data/postgresql.conf
#listen_addresses = 'localhost'    修改为
listen_addresses = '*' 

cat  /usr/share/doc/packages/zabbix-server/postgresql/schema.sql | bin/psql zabbix  (这样执行是超级用户的表)
cat  /usr/share/doc/packages/zabbix-server/postgresql/schema.sql | bin/psql -h 127.0.0.1 -p 5432 -d zabbix -U zabbix -W 
//如果要为zabbix-proxy的数据库，就不用下面两行了
cat images.sql | sudo -u zabbix psql zabbix
cat data.sql | sudo -u zabbix psql zabbix
---

/etc/zabbix/zabbix_server.conf 
	#DBSocket= 关闭MySQL选项 
	DBHost=localhost #localhost表示使用mysql，其它情况(注释这行)表示使用postGreSQL
	#DBSchema=public	
	#DBPort=5432
	DBPort=3306
	DBName=zabbix 
	DBUser=zabbix
	DBPassword=zabbix
	DBSocket=/tmp/mysql.sock

	SourceIP=  #当zabbix-server有多个网卡,使用哪个发出数据
	ListenPort=10051  #与zabbix-agent通讯
	# JavaGatewayPort=10052
   LogFile=/var/log/zabbix/zabbix_server.log

/usr/sbin/zabbix_server  启动报读配置权限 ，写日志权限问题


systemctl list-units  
systemctl list-unit-files | grep zabbix-server
systemctl start zabbix-server

----nginx
vi /etc/nginx/conf.d/zabbix.conf 放开下面做修改

# listen 80;
# server_name example.com;

文件中有
location ~ [^/]\.php(/|$) {
	fastcgi_pass    unix:/run/zabbix-php-fpm.sock;
	fastcgi_split_path_info ^(.+\.php)(/.+)$;
	fastcgi_param   DOCUMENT_ROOT   /usr/share/zabbix;
	fastcgi_param   SCRIPT_FILENAME /usr/share/zabbix$fastcgi_script_name;
   fastcgi_param   PATH_TRANSLATED /usr/share/zabbix$fastcgi_script_name;</pre>
}

http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_split_path_info

 cp /etc/php7/fpm/php-fpm.conf.default /etc/php7/fpm/php-fpm.conf  # 官方文档少了这步

 cp -n /etc/php7/fpm/php-fpm.d/www.conf{.default,}  #-n表示不覆盖已经存在的文件
 #结果是 cp /etc/php7/fpm/php-fpm.d/www.conf.default  /etc/php7/fpm/php-fpm.d/www.conf 
 			  [www]区默认有listen = 127.0.0.1:9000,
 			  
 vi /etc/php7/fpm/php-fpm.d/zabbix.conf 
 		;默认有		
		[zabbix]
		user = wwwrun
		group = www
		listen = /run/zabbix-php-fpm.sock 
		listen.owner = nginx
		listen.allowed_clients = 127.0.0.1

  		; php_value[date.timezone] = Europe/Riga  ;放开修改正确的时区 Asia/Shanghai
	



# systemctl restart zabbix-server zabbix-agent nginx php-fpm
# systemctl enable zabbix-server zabbix-agent nginx php-fpm

----Zabbix apache 
老的3版本 安装 zabbix-phpfrontend-3.0.27-lp151.1.1.x86_64.rpm  
	openSUSE-leap-15.1 DVD带的依赖
	rpm -ivh  php7-xmlreader-7.2.5-lp151.5.44.x86_64.rpm php7-7.2.5-lp151.5.44.x86_64.rpm php7-iconv-7.2.5-lp151.5.44.x86_64.rpm php7-dom-7.2.5-lp151.5.44.x86_64.rpm php7-tokenizer-7.2.5-lp151.5.44.x86_64.rpm php7-pdo-7.2.5-lp151.5.44.x86_64.rpm php7-json-7.2.5-lp151.5.44.x86_64.rpm php7-ctype-7.2.5-lp151.5.44.x86_64.rpm php7-xmlwriter-7.2.5-lp151.5.44.x86_64.rpm php7-sqlite-7.2.5-lp151.5.44.x86_64.rpm ../noarch/system-user-wwwrun-20170617-lp151.4.70.noarch.rpm

有 /etc/apache2/conf.d/zabbix.conf   还要DVD 安装apach2的包,systemctl start apache,journal -xe看日志 ，如日志右边看不全，使用右键头

#启用apache模块 php
a2enmod php7 因为安装的是apache2-mod_php7 (文档上说zabbix-3不支持php7,测试最后可以使用frontend)

#启用ZABBIX标志，为/etc/apache2/conf.d/zabbix.conf文件使用
a2enflag ZABBIX 

vi /etc/php7/apache2/php.ini进行修改 
----

访问 http://127.0.0.1/  进入setup.php配置界面

--提示失败项 
					 			Current value	Required	
PHP option "post_max_size"			8M			16M	Fail
PHP option "max_execution_time"	30			300	Fail
PHP option "max_input_time"		60			300	Fail
PHP databases support				off		 		Fail
PHP gettext								off				Warning  用于汉化包 (php7-gettext)

DVD安装 php7-mysql 或 php7-pgsql
--
可配置数据库IP,端口,数据库名，schema(默认public),用户名，密码 
有配置Zabbix server IP和端口(10051)

http://127.0.0.1  进行访问 默认的用户名大写A／密码为 Admin/zabbix   

zabbix_server有很多进程
监控组
	zabbix_server: poller 拉取数据用的
	zabbix_server: trapper 接收agent上报数据用的
	zabbix_server: icmp pinger  用来ping存活检测
	zabbix_server: timer  时间及告警维护
	zabbix_server: unreachable poller  无法到达的

管理组
	zabbix_server: history syncer   数据分析保存到数据中
	zabbix_server: housekeeper  定时清理历史数据
	
	zabbix_server: alert manager  告警管理
	zabbix_server: alerter 告警
	zabbix_server: escalator  (escalator 逐步上升)处理告警,如升级
	zabbix_server: discoverer 设备自动发现 


-----Zabbix界面
Administrator->User ->点用户 ->language选择 zh_CN->update按钮  
Administrator -> General -> 过默认右边下拉是 GUI-> Default theme 可选择 Dark

增加被监控的主机
Configuration->Hosts->create host按钮-> Host name (一定要和zabbix-agent配置 Hostname相同) ,Visible name 显示的别名
	Groups 中选择组,如没有可直接在里面输入提示新建这个组
	Agent interfaces 中可增加一个主机的多个网卡,IP或DNS(用主机名好像不行) 写一个即可
	如有proxy,在Monitored by proxy中选择
	在Template标签中,可增加 [Template OS Linux by Zabbix agent] 可以增加多模板(建主机时带模板,后如unlink模板Graph的数据会断)

建立后如在表格中有显示绿色的ZBX表示正常
Monitor->Latest data-> 一定要选择条件才出数据,如Hosts选择已经有的 -> 可点Graph看图,如自已的监控项显示为灰色说明有问题,查主机里的报错信息(不是模板里的)

自定义模板
Configuration->Template ->Create Template->起名,选组,建立后
在表格中编辑点入 -> Applications->create application 起名 建立后
在表格中 Items 编辑点入 -> create Item->

也可建立自己的监控项
Configuration->Hosts->建立好主机行中的 	Items 列 -> create item按钮 -> Name中起个名->
	Type中如选择External check 可自己指定一个脚本
	Type中如选择SSH agent
	Type中选择 zabbix agent(Active),Key 中按select弹窗做选择 net.if.in[if,<mode>] 网卡流入, []中为参数,<>表示可选的有默认值 ,修改net.if.in[ens33]
	Type of information 指定采集的数据类型 numberic(unsigned) ,Unit是单位 ,Update interval默认1m 可修改为20s
		 History storage period保存多长时间数据,Trend storage period  趋向数据(图),Show value默认as is,New application起个名字显示在表格中

Monitor->Dashboard->  Global view -> Number of hosts 显示 ,Number of items 

Monitor->Graphs->选组,主机,图 如Cpu usage,Memory usage,Interface wlan0:Network traffic(是模板里建立的Graph),默认是1小时,apply按钮 就可看图(也可View as中下拉Values看数据)
对已经有模板可以增加自己的Graph,Item只能选择模板加过的
对已经有主机可以增加自己的Graph

Monitor->Screens (多个Graph集中显示),这里可以建立screen,和主机相关的,但不是从模板带出来的

Template中建立Screen 如2行,2列,在表格中点Constructor->每个格增加Graph也可是clock,URL,plan text(也是graph)
主机中的screen是模板中设计的做显示,但查看要使用搜索工具,搜索主机名,点表格有	Screens链接,正常不显示

--web监控
模板中-> Web scenarios ->做新建 ,step标签中add(可多个),起名 和 输入网址,可复选 Follow redirects,在Required string中输入想要的返回值
主机中->Web scenarios -> 默认有一个和模板一样的,显示名字前有 模板名字: ,但有些东西不能修改(如名字),有些可以(如URL)

Monitor->Web 前面有起中文,在图的标题上中文显示方块 

windows 字体文件如simhei.ttf 复制 /usr/share/zabbix/assets/fonts/ 下
vi /usr/share/zabbix/include/defines.inc.php 
找 ZBX_GRAPH_FONT_NAME 和 ZBX_FONT_NAME 把值修改为windows字体文件名,如simhei(默认值为 graphfont)

-------告警
模板中-> Trigger -> create trigger 按钮->输名字,选级别,Expression 边点Add -> 选择对应的 Item -> function中选择函数

nodata(30m) 函数 表示在指定时间内没有收到zabbix-agent 的数据就报警
last() 函数 表示最新一次取到的值,如不满足条件 就报警
diff() 函数 表示两次取值不一样 就报警
avg(5m)函数 表示指定时间 的平均植 ,如不满足条件 就报警
change()函数  与diff类似

Monitor->Dashboard->Problems 面板 会显示有问题的trigger,Ack列 , Action列
Monitor->Problems  -> Show 项旁边点History按钮看历史记录,如发邮件失败这里可看原因

--用户组  
Administration->User groups -> create user group ->输入组名,permissions标签 增加主机组(即 建立host时的组名),按钮选中权限(Read-Write,Read)-> Add
Administration->Users ->create user ->permissions标签 -> User type选zabbix user,显示对应组权限 

Administration->Media types-> create media type按钮->Type 选择 Script,Script name写文件名,如zabbix-mail.sh ->
	增加三个参数写宏变量  {ALERT.SENDTO},{ALERT.SUBJECT},{ALERT.MESSAGE}

Administration->Users ->选中用户 -> media标签->Type 选建立的Media,Send to收件人,选哪些级别

Configuration->Action->Event source 默认选中trigger->create actoin按钮->输入名字,New condition中
	下拉 problem is supressed 值为 No,表示不是在维护模式 ->	Add
	下拉 Trigger severity,is greater than or equals, 值为Warning ->	Add
 	operation 标签是邮件是标题,内容,里面有很多宏变量 ->Operations 栏中 Add-> Operation type 选send message, 
 		Send to User groups中选用户组,
 		Send only to中选中建立的Media
		Operation condition中Add后生成 默认为 Event Acknowledged ,equas,Not Ack ->Add确认
 	recovery operation 标签 与	operation 标签 类似
 	
 	
zabbix_server.conf 中默认配置
AlertScriptsPath=/usr/lib/zabbix/alertscripts

目录中建立shell脚本
---vi /usr/lib/zabbix/alertscripts/zabbix-mail.sh
#!/bin/bash
SENT_TO=$1
SENT_SUBJECT=$2
SENT_CONTENT=$3
SENT_CONTENT_FILE="/tmp/zabbix_mail_content_$$.tmp"
echo $3 >  $SENT_CONTENT_FILE
dos2unix $SENT_CONTENT_FILE

echo "to ${SENT_TO}, title ${SENT_SUBJECT}, contnet ${SENT_CONTENT}" >>/opt/zabbix_mail.log
#echo "${SENT_CONTENT}"| mailx -s "${SENT_SUBJECT}" ${SENT_TO} #内容以附件形式发送
#mailx -s "${SENT_SUBJECT}" ${SENT_TO} < $SENT_CONTENT_FILE   #内容以文本形式发送
---  
--- 
要保证服务器的sendmail和postfix服务是关闭的 
163邮箱网页,设置->客户端授权密码标签->开启

yum install mailx
vi /etc/mail.rc
set from=xxx@163.com
set smtp=smtp.163.com
set smtp-auth-user=xxx@163.com
set smtp-auth-password=yyy
set smtp-auth=login 

测试发给自己
 echo "content test"| mailx -s "title test" xxx@163.com

---
-----自定义 宏
Administration->General->右边下拉Macros ,变量格式  {$SNMP_COMMUNITY}
模板中也有 Macros,可应用于trigger
-----自动发现 宏
模板中 有Discovery列 ,模板详细页有Discovery rules 标签->filter标签 -> 宏变量格式为 {#xxx}

-----正则表达式
Administration->General->右边下拉 Regular Expression
-----
模板trigger的名字处做测试 ,可用{{ITEM_VALUE}.regsub("0","宏变量结果正常")}  
	#ITEM_VALUE表示监控项最新的值,regsub是宏变量函数,第一个参数正则表达式


---- 安装Java gateway 使用JMX
 源码编译使用  ./configure --enable-java --prefix=$PREFIX
仓库上有  zabbix-java-gateway-4.4.4-1.el15.x86_64.rpm    或 zabbix-java-gateway-4.4.4-1.el7.x86_64.rpm 

----zabbix-agent linux版 被监控端 
	DVD   中自带的 noarch/system-user-wwwrun-20170617-lp151.4.70.noarch.rpm
	 
vi /etc/zabbix/zabbix_agentd.conf
	Server=127.0.0.1     	#指定zabbix-server或zabbix-proxy的IP ,应是外网IP,用主机名好像不行 ,被动监控
	ServerActive=127.0.0.1  #指定zabbix-server或zabbix-proxy的活动检查IP,主动监控
	Hostname=  # 要与zabbix-server端配置的要相同  Configuration->Hosts->create host按钮-> host name 
	
	ListenPort=10050  #zabbix-agent的监听端口用来连接agent-server使用的
	LogFile=/var/log/zabbix/zabbix_agentd.log
	
	

在所有的监控机器上运行
/usr/sbin/zabbix_agentd
或用 systemctl restart zabbix-agent 

systemctl enable zabbix-agent 

----zabbix-agent windows 版
zabbix_agents-4.4.4-win-amd64-openssl.zip

配置 注意LogFile 位置


安装为一个服务
bin/zabbix_agentd --config c:/zabbix_agents/conf/zabbix-agent.win.cnf --install 
启动服务
bin/zabbix_agentd --config c:/zabbix_agents/conf/zabbix-agent.win.cnf --start

tasklist | findstr zabbix

模板选择Windows的   	Template OS Windows by Zabbix agent

windows 防火墙关闭
 



--- agent-server 端安装运行  zabbix-get
zabbix-get -s192.168.6.132 -p 10050 -k mysql.ping  
报 Check access restrictions in Zabbix agent configuration

 
--- 也可在 agent-agent 端安装运行  zabbix-sender
 
 

---docker版本

docker pull zabbix/zabbix-server-mysql
docker run --name some-zabbix-server-mysql -e DB_SERVER_HOST="some-mysql-server" -e MYSQL_USER="some-user" -e MYSQL_PASSWORD="some-password" -d zabbix/zabbix-server-mysql:tag
 


========================== SonarQube
支持插件安装

使用见Dev_software

有 docker版本  docker pull sonarqube
解压下载的 sonarqube-7.8.zip (Community版本)
sonarqube-8.5 要求jdk11,jdk15不行，最高支持PostgreSQL-12
--演示安装
# On Windows, execute:
C:\sonarqube\bin\windows-x86-xx\StartSonar.bat

# On other operating systems, as a non-root user execute:
/opt/sonarqube/bin/[OS]/sonar.sh console


http://localhost:9000   admin/admin

建立项目 javase

mvn sonar:sonar \
  -Dsonar.projectKey=javase \
  -Dsonar.host.url=http://localhost:9000 \
  -Dsonar.login=0c6504415bca44d63d0dc1074e8fb3462aef1d8e  是页面中提示生成的码
  
-- 生产环境安装
支持数据库有 SQL Server, Oracle,PostgreSQL
 
解压目录logs/sonarqube.log看日志, 
	设置内核参数普通不会立即生效，可能要重启
	elastic search不能以root用户启动
	
--PostgreSQL
不使用默认的public

ALTER USER sonar SET search_path to mySonarSchema;

--- 
sysctl vm.max_map_count 最好>= 262144
sysctl fs.file-max 最好>=65536


sysctl -w vm.max_map_count=262144
sysctl -w fs.file-max=65536
#ulimit -u 4096

/etc/sysctl.conf
vm.max_map_count=262144
fs.file-max =65536


/sbin/sysctl -p

cat /proc/sys/fs/file-max

 
 
openSUSE-leap-15.1 下的 /etc/sysctl.conf文件有提示 sysctl 会读下面文件
#   /boot/sysctl.conf-<kernelversion>
#   /lib/sysctl.d/*.conf
#   /usr/lib/sysctl.d/*.conf
#   /usr/local/lib/sysctl.d/*.conf
#   /etc/sysctl.d/*.conf
#   /run/sysctl.d/*.conf
#   /etc/sysctl.conf



/etc/security/limits.conf
*  		 soft   nofile   65536
*  		 hard   nofile   65536
sonarqube   -    nproc    4096

#  nproc - max number of processes
#  nofile - max number of open file descriptors

添加session required pam_limits.so 到 /etc/pam.d/login中


如使用systemd服务，即systemctl
[Service]
...
LimitNOFILE=65536
LimitNPROC=4096

vi /etc/systemd/system.conf 
DefaultLimitNOFILE=65536
DefaultLimitNPROC=4096

man systemd-system.conf

ulimit -u  默认30792  the maximum number of user processes
ulimit -n  默认1024	the maximum number of open file descriptors

ulimit -Hn  H=Hard    发现只有root 用户生效，普通用户没用，放在/etc/profile 中普通用户又没权限执行,原因是要修改/etc/systemd/system.conf 才对普通用户生效(elasticsearch,redis也要)
ulimit -Sn  S=Soft


参考文档 https://www.freedesktop.org/software/systemd/man/systemd.exec.html
 
使用 Elasticsearch 默认使用 seccomp (SECure COMPuting) filter

检查内核是否使用了 seccomp,
grep SECCOMP /boot/config-$(uname -r)
	CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
	CONFIG_SECCOMP_FILTER=y
	CONFIG_SECCOMP=y
如结果不是上面的说明没有激活SECCOMP, 要打开 /opt/sonarqube-7.8/conf/sonar.properties 文件配置 sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false

--PostgreSQL
bin/createdb sonarqube
bin/psql sonarqube
	CREATE USER sonarqube;
	ALTER USER sonarqube WITH password 'sonarqube';
	-- CREATE DATABASE kong OWNER kong;
	alter database sonarqube owner sonarqube；


sonar.jdbc.username=sonarqube
sonar.jdbc.password=sonarqube
sonar.jdbc.url=jdbc:postgresql://127.0.0.1:5432/sonarqube

除Oracle外的其它JDBC jar都是提供的 , 解压目录/extensions/jdbc-driver/oracle ,
解压目录/lib/有mysql的驱动,但配置文件中说不支持MySQL了

配置Elasticsearch storage位置,默认是解压目录的data目录
#sonar.path.data=data
#sonar.path.temp=temp

sonar.web.host=0.0.0.0
sonar.web.port=9000
sonar.web.context=/sonarqube


bin/[OS]/sonar.sh start
bin/linux-x86-64/sonar.sh  start  启动要花点时间 


http://127.0.0.1:9000/sonarqube    界面会显示正在启动 login-> admin/admin

---汉化
https://docs.sonarqube.org/latest/extend/i18n/
org/sonar/l10n/<plugin key>_<language>.properties

https://github.com/SonarQubeCommunity/sonar-l10n-zh  查兼容版本 下载 sonar-l10n-zh-plugin-1.28.jar
.jar包中有 org/sonar/l10n/core_zh.properties

将其放在./extensions/plugins/目录下,重启SonarQube 
Administration->Marketplace->输入chinese搜索发现已经安装了
浏览器也要设置语言为中文是第一个，测试成功


------------Afresco 收费  内容管理CMS


------------Confluence 收费 在线写文档


------------ JIRA Software 8.2.2 收费 try free
Java开发

su root (也可不用root,但要手工指定安装目录/opt/atlassian/jira )
./atlassian-jira-software-8.2.2-x64.bin  交互提示安装
OK [o, Enter], Cancel [c]
按回车

Express Install (use default settings) [1], Custom Install (recommended for advanced users) [2, Enter], Upgrade an existing JIRA installation [3]
输入1

Installation Directory: /opt/atlassian/jira 
Home Directory: /var/atlassian/application-data/jira 
HTTP Port: 8080 
RMI Port: 8005 
Install as service: Yes 
Install [i, Enter], Exit [e]
输入i

Start JIRA Software 8.2.2 now?
Yes [y, Enter], No [n]
输入y

就可打开 http://localhost:8080 一进页面就可选中文 -> 
	我将设置它自己 ->其它数据库 (推荐用于正式生产环境)-> 支持MySQL5.7+/PostgreSQL/Oracle

---MySQL
create database jira character set utf8 collate utf8_bin;
create user jira@localhost identified by 'jira';
grant all privileges on jira.* to jira@localhost ;
ALTER USER jira@localhost IDENTIFIED WITH mysql_native_password   BY 'jira';

create user jira@'%' identified by 'jira';
grant all privileges on jira.* to jira@'%' ;
ALTER USER jira@'%' IDENTIFIED WITH mysql_native_password   BY 'jira';

---
设置数据库主机，用户名，密码，数据库，报 找不到驱动：com.mysql.jdbc.Driver
要license key的


启动：
[jira_home]/bin/start-jira.sh
停止：
[jira_home]/bin/stop-jira.sh
提示 CATALINA_HOME:   /opt/atlassian/jira
 
 

--------- 禅道项目管理软件 -11.5.1
有中文版 有国际版，有源码版本，有linux二进制版本
开源  用PHP开发 用 Apache和MySQL

源码包安装(禅道英文名 ZenTao)
	将其解压缩，得到zentaopms目录。拷贝到webserver对应的目录，比如Apache2在openSUSE的默认目录 是/srv/www/htdocs 
	通过浏览器访问http://ip:端口/zentaopms/www/index.php，系统会自动转入安装程序。 


a2enmod php7
sudo chown -R dell /srv/www/htdocs/
cp -r ./zentaopms/* /srv/www/htdocs/
systemctl start apache2
http://127.0.0.1/www/install.php 有语言可以切换 

会做一些检查，如下失败项
PDO_MySQL 			Not Loaded							Failed(×) 	Edit php.ini to load PDO_MySQL extension.
Zlib Extension 	Not Loaded 							Failed(×) 	Edit php.ini to load zlib extension.
Curl Extension 	Not Loaded 							Failed(×) 	Edit php.ini to load curl extension.
Temp Directory 	Found Not Writable 				Failed(×) 	"/srv/www/htdocs/tmp/" permison has to be changed.
																				Run chmod o=rwx -R /srv/www/htdocs/tmp/ to change it.
Uploaded File Directory 	Found Not Writable 	Failed(×) 	"/srv/www/htdocs/www/data" permison has to be changed.
																				Run chmod o=rwx -R /srv/www/htdocs/www/data to change it. 
根据提示执行
chmod   o=rwx -R /srv/www/htdocs/tmp/
chmod   o=rwx -R /srv/www/htdocs/www/data

vi /etc/php7/apache2/php.ini  有如下，不必动
;extension=curl
;extension=pdo_mysql

yast在线安装 php7-curl,php7-zlib, DVD安装 php7-mysql,php7-pdo(已经安装)

页面提示配置数据库,表前缀默认配置为zt_，可以选择语言
create database zentao character set utf8 collate utf8_bin;
create user zentao@localhost identified by 'zentao';
grant all privileges on zentao.* to zentao@localhost ;
ALTER USER zentao@localhost IDENTIFIED WITH mysql_native_password   BY 'zentao';

create user zentao@'%' identified by 'zentao';
grant all privileges on zentao.* to zentao@'%' ;
ALTER USER zentao@'%' IDENTIFIED WITH mysql_native_password   BY 'zentao';

会花点时间初始化执行SQL
提示将屏幕内容保存到 /srv/www/htdocs/config/my.php 中 (要新建文件)
<?php
$config->installed       = true;
$config->debug           = false;
$config->requestType     = 'GET';
$config->timezone        = 'Asia/Shanghai';
$config->db->host        = '127.0.0.1';
$config->db->port        = '3306';
$config->db->name        = 'zentao';
$config->db->user        = 'zentao';
$config->db->password    = 'zentao';
$config->db->prefix      = 'zt_';
$config->webRoot         = getWebRoot();
$config->default->lang   = 'zh-cn';
?>

提示配置 管理员帐号，完成后提示 请/srv/www/htdocs/www 目录下的 install.php 和 upgrade.php 文件 
只有删除后才可进入登录页，初始登录会要求修改密码，要复杂的密码才行。



---------Nagios 监控  


---------Cacti  监控 可以图形监控Apache MySQL,邮件报警
是一个 php 源码的


---------mrtg   Multi Router Traffic Grapher  监控网络链路流量负载
SNMP

源码安装依赖于libgd

yum install mrtg 
/etc/mrtg/mrtg.cfg

========================== Jenkins 使用见Dev_software  
========================== Teamcity 使用见Intellij idea
========================== BugTracker 使用见Dev_software
 
 
 