
UI工具
redis-desktop-manager-0.9.1  可以监控，可写命令好用

redisclient-win32.x86_64.2.0.jar
RedisStudio-en-0.1.5.exe  不能写命令，不能看数据值
-----phpRedisAdmin   测试成功(nginx)
有Docker 镜像 docker run --rm -it -e REDIS_1_HOST=myredis.host -e REDIS_1_NAME=MyRedis -p 80:80 erikdubbelboer/phpredisadmin

依赖于pRedis ,一个php连接redis的库 https://github.com/nrk/predis/
把下载的predis-1.1.zip解压放在phpRedisAdmin下的vendor(没有要新建)目录中

cd phpRedisAdmin
git clone https://github.com/nrk/predis.git vendor

就不用在php.ini中增加extension=xxx

includes/config.sample.inc.php  中有配置连接redis服务的IP和端口,可配密码


============== Redis  编译安装 CentOS 7
windows 版 redis-3.2.100
https://github.com/MicrosoftArchive/redis/releases

http://download.opensuse.org/distribution/leap/15.1/repo/oss/ 下的 x86_64/ 
	redis-4.0.11
http://download.opensuse.org/tumbleweed/repo/oss/x86_64/
	redis-  现在是 5.0.5
	

	
Redis 单线程 将每个客户端都关联一个指令队列
	指令队列中的指令是顺序执行的，但是多个指令队列中的指令是无法保证顺序
	一个响应队列中的消息可以顺序的回复给客户端，多个响应队列之间是无法保证顺序的

单线程避免了线程切换和竞态产生的消耗
	纯内存访问
	非阻塞式IO
	IO多路复用
	
Redis6.0 IO多线程其实指客户端交互部分的网络IO交互处理模块多线程，而非执行命令多线程

----redis 4.x

如报error: jemalloc/jemalloc.h: No such file or directory  
用 make MALLOC=libc 就OK ,Mac用jemalloc(README文件中说的)


make test 要 tcl-8.5以上(CentOS 7DVD自带8.5.13),可用8.6.7  测试OK,
	redis-trib.rb 还是要ruby>2.2.2(CentOS 7DVD自带2.0) 有ruby-2.5.0编译安装后(./configure  , make , make install)带 gem 命令(RubyGems)，还要ruby的redis依赖
	gem list
	gem install redis 

				
	可以从https://rubygems.org/ 上搜索redis 点download链接 下载文件redis-4.0.1.gem
	gem install --local redis-4.0.1.gem   
		如报错 cannot load such file -- zlib 
			cd ruby-2.5.0/ext/zlib
			ruby ./extconf.rb  报很多 no  ,yum install zlib-devel 就可以了
				
				如报No rule to make target `/include/ruby.h', needed by `zlib.o'.
				vi Makefile  修改 zlib.o: $(top_srcdir)/include/ruby.h 改成 zlib.o: ../../include/ruby.h
			make
			make install
	安装OK
	

-------------redis 5.0.5
cd src 
make
sudo make install

在 openSUSE-15 下源码编译安装OK (没提示要ruby,tcl,jemalloc)

/usr/local/bin/redis-server 启动

提示 加 vm.overcommit_memory = 1 到  /etc/sysctl.conf ,用命令 sysctl vm.overcommit_memory=1立即生效
cat /proc/sys/vm/overcommit_memory
0 表示内核将检查是否有足够的可用内存供应用进程使用:如果有足够的可用内存,内存申请允许. 否则,内存申请失败,并把错误返回给应用进程。
1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。
 
 警告执行
 echo never > /sys/kernel/mm/transparent_hugepage/enabled   
 放/etc/rc.local 中开机启动执行  
 (openSuSE-15 中在 /etc/init.d/boot.local 文件中或 /etc/rc.loca 添加无效 ??? )
 Red Hat系统的对应文件是/etc/rc.d/rc.local 
 
 
echo 511 > /proc/sys/net/core/somaxconn
或者
--vi /etc/sysctl.conf
net.core.somaxconn= 1024
更新执行 sysctl -p


 
最大打开文件数 (openSUSE无效？？？？elasticsearch也要设置这个)
/etc/security/limits.conf
*          soft    nofile  1024
*          hard    nofile  10032

ulimit -Sn  1024
ulimit -Hn 10032

-------------redis 6.0.1
在 openSUSE-15 下源码编译
 
cd src   #也可以不切换src
make MALLOC=libc   #要 jemalloc/jemalloc.h 是MacOS用的
#make BUILD_TLS=yes 


成功后src目录下有二进制
sudo make install 安装在 /usr/local/bin/

redis-server  --version



-----------
redis-server -v 看版本
./redis-server ( 默认监听 6379 端口)

源码目录有redis.conf可用于复制
cp redis.conf  /usr/local/etc/
redis-server /usr/local/etc/redis.conf


默认配置 protected-mode yes 修改为 no

bind 默认127.0.0.1  是不能外网连接的，要修改为本机IP 或者注释它,或者修改为0.0.0.0

./redis-server --port 9999 --slaveof 127.0.0.1 6379  自己做从,--slaveof 后的是masterIP masterport  #slaveof 在redis 5.0过时，使用 REPLICAOF
./redis-server /etc/redis/6379.conf --loglevel debug 

./redis-cli -p <port>  -h <hostname>  有交互命令如ping
>help 再按tab有命令组的提示,如@string
 help brpop
>bgsave  保存到磁盘  使用LASTSAVE 命令判断 BGSAVE 命令是否执行成功
>save   保存到文件(默认 dump.rdb 可以在线保存导出给另一个redis,failover是这样实现的)
	append only file 以aof结尾(appendonly.aof) 配置文件中加 　appendonly yes

>info 可以看到服务器版本，及很多信息，有replication

>shutdown 关闭服务端
>exit 退出本客户端



数据类型有 字串(integer,float)，bit arrays(bitmap),list,set,zset,hash,HyperLogLogs,Stream(5版本新的数据类型),geo开头的spatial

>set <var> <val>
>get <var>
>set name "john doe"
> append name " mr."
> strlen name 
> substr name 0 3 
>mset age 30 sex "male"
msetnx age 30 sex "male"
>mget age sex

set greet helo
setrange greet 2 x   #返回 hexlo  ,格式 setrange key offeset value 
setrange greet 2 LL  #返回heLLo 

getrange greet 2 3 #格式 getrange key  start end
getrange greet 2 -1

>set counter 10
>incr counter      	加1  原子操作
>incrby counter 10  加10
incrbyfloat counter 0.5
>decr counter     	减1
>decrby counter 10  减10
>getset counter 45  先返回再设置

大小写 
 A 的ASCII 是 65   0100  0001
 a 的ASCII 是 97   0110  0001
 区别就是第3位0或者1的区别
 
set char 'A'
(bitmap类型)
setbit char 2 1  #(左边高位)第3位设置为1,变小写,格式setbit key offset value
getbit char 2

get char 是a
bitcount char 显示3
 
set v 2
get v 显示字串2 ascii 是 0011 0010
 
bitop  or res char v 

0110 0001
0011 0010
----------
0111 0011	 是小写s

get res 结果s
 
 
bitop  and res char v




---list
lpush message " -- " 
lpop message
rpush message "hello"   #也有 lpush从左边加
rpush message "world"
rpoplpush message dest #格式 rpoplpush  source dest
lrange message 0 2		开始索引,结束索引,-1表示最后一个元素，-2表示list中的倒数第二个元素
lrange message 0 -1
llen message 
lrem message 1 "hello"     从左删1个hello
linsert message before "world" "hello"   ##在 world前加hello
ltrim message 1 2     #从左开始索引 结束索引 ,删总数1个
brpop message 2 #超时时间2秒 相应的有blpop
lset message 0  val0
lindex message 0

---set
sadd myset 'one'  
sadd myset2  'one'  
sadd myset2 'three' 

smembers myset
sismember myset 'one'    是否存在元素  
sdiff myset1 myset2
sinter myset2 myset 取交集
sunion myset2 myset 
sdiff myset2 myset
sort myset2 alpha  desc
srem myset2 'one'   
spop myset2   随机取一个
srandmember myset2 随机取一个,不删
scard myset2  集合个数
smove myset2 destSet 'three'  
 
sinterstore res myset1 myset2 
sdiffstore
 

---有序set
zadd myscore 80 'math'  #score 是80
zadd myscore 77 'english'
zadd myscore 78 'chinese' 79 'hisotory'
zrank myscore 'hisotory'  #得到排名,以0开始的
zrevrank myscore 'hisotory'

zcard myscore 		#总数
zscore myscore 'math' 
zcount myscore 70 80 
zrange myscore 0 -1  #根据分数的名次
zrange myscore 0 -1  withscores  
zrevrange  myscore 0 -1
zrangebyscore myscore -inf 80  #根据分数  负无穷
zrangebyscore myscore -inf 80 limit 1 2  # limi后是 offset count
zrangebyscore myscore  77 78

zincrby myscore 2 'hisotory'
zrem myscore 'hisotory'
zremrangebyscore myscore 77 78  #包括办界的范围内
zremrangebyrank myscore 1 2  #根据排名删，包括办界的范围内

zadd zset2 68 'chinese' 69 'hisotory'

zinterstore zres 2 myscore zset2   #2是相同的,必须是对的
zrange zres 0 -1  withscores 得到的是分数相加
zinterstore zres 2 myscore zset2 aggregate max
zinterstore res 2   myscore zset2 weights 1 2 aggregate max  #对zset2的集合分数做*2
类似的有 zunionstore
 


--hash
hmset kid name Akshi age 2 sex Female 
hset kid  brothers 2
hsetnx kid name 'wang'
hkeys kid
hvals kid 
hget kid name
hmget kid name age sex 
hgetall kid 
hdel kid sex 
hlen kid 
hexists kid name
hincrby kid age 3
hincrbyfloat kid age 0.5


---map数据导出
---hgetall.lua
return redis.call("HGETALL",KEYS[1]);
---
redis-cli  -h 127.0.0.1 -p 6379 --csv --eval hgetall.lua >/tmp/redis_map.csv
这个输出没有行号,加--csv 全部数据放一行，会把" 置换为 \", 查找替换 加命令
cat cmd.csv | redis-cli -h 127.0.0.1 -p 6379 --pipe   (powershell可以用cat)


一个终端 客户端订阅 会阻塞
> subscribe mychannel_1  mychannel_2 	
> psubscribe mychannel_*   通配式pattern	
##unsubscribe 
也可再开一个终端 subscribe mychannel_1 

另一个终端
> publish mychannel_1 hello   #会返回2,表示2个被接收
> publish mychannel_2 world

pubsub 命令


----管理
select 0  多个DB切换    #最多数据库配置项 databases 16,即最多select 15
select 1 
MOVE name 0		DB移动 
DBSIZE  当前库的key的个数
info		显示所有配置
FLUSHDB    清当前DB
FLUSHALL   清所有的key
del   <theKey>
type dest 集合是什么类型的

TTL 命令可以获取某个key值的过期时间(-1表示永不过期)

set name "john doe"
ttl name

exists name
expire name 5 			5秒
expireat name 1316805000  (seconds since January 1, 1970) 在某个时间点过期
persist name 移除过期时间

keys * 显示所有的key
del name

randomkey
rename name new_name
ping  测试连接是否存活的
config get dir 也可用  config get *
用config set 可以不用重启,修改配置
time 返回服务器时间

-----事务，严格上不能算事务
NX结尾命令都是判断在这个值没有时才进行某个命令
SET name "John Doe"
SETNX name "Dexter Morgan"  因已有值,所以未改变
setex name 10 'lisi'  #10秒过期

GETSET name "Dexter Morgan"
GET name 

SET inAcc 10 
SET outAcc 20
MULTI 			#事务开始
INCR inAcc 	#提示QUEUED 排队
#incr name   #这里对字串加1失败不会导致前后的回滚 (不是想要的), 只有这里输入了语法错误的命才回滚（程序中命令事先写好没问题）
decr outAcc 
DISCARD 		#回滚
EXEC 			#提交事务

---- 乐观锁

set ticket 1
watch ticket
multi
incr ticket  #提示QUEUED
exec  #这里如果另一个session也修改了ticket，这里再执行会返回nil 表示执行失败，即前的incr ticket被放弃

#执行exec ,discard,unwatch 时会自动取消watch


---分布式锁 Java client 实现  Redisson 

---Lua 
官方说lua脚本的原子性 Atomicity of scripts,如脚本正在执行，其它命令或脚本不能执行

eval "return redis.call('set','foo','bar')" 0 

call  如有错误则,返回给调用者
pcall 如有错误会 trap一个表

EVALSHA 同eval 但参数是SHA1 加密的


>eval "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
1) "key1"
2) "key2"
3) "first"
4) "second"

中的2表示有两组key ,下标从1一始(全局变量 KEYS,ARGV,是接受后面的参数)
 
>eval "return redis.call('set',KEYS[1],'bar')" 1 foo
>get foo 显示 bar



查看错误信息
redis.error_reply(error_string)
redis.status_reply(status_string)

lua脚本实现分布式锁，可以保存证setnx,expire两个操作的原子性
如lua脚本没有执行完成时，不能执行其它脚本
  
--官方SETNX文档的锁方案
SETNX lock.foo <current Unix time + lock timeout + 1>如返回0表示失败,看时间是否超时(对前一个加锁的进程死了)
如0查是否>当时前,如过期(这也是一步操作,不能保证 这个和GETSET是原子的 )
GETSET lock.foo <current Unix timestamp + lock timeout + 1> 就算这个返回值是早于当前时间,取锁失败(被快的抢了),这时要等(但也已经设置了新值)
用完DEL lock.foo ,有一种情况是不知道会锁多长时间,设置锁2秒,但5秒才完事,此时就会被其它的取到锁???

如果值是写死的形式，如果setnx成功得锁，但在del之前客户端节点挂了，就一直锁了

--官方 分布式锁文档的方案(单实例),但set命令没说是单实例
设置key时指定超时时间(PX单位毫秒,EX单位是秒)，NX如不存在则设置，XX如存在则设置，成功返回OK,失败返回nil
SET resource_name my_random_value NX PX 30000
也存在相同问题，有一种情况是不知道会锁多长时间,设置锁2秒,但5秒才完事,此时就会被其它的取到锁???

随机值是为了安全释放锁
如要释放锁使用 lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end

--java 实现分布式锁 可用 redisson，还是连接断，锁释放比较好

--redis.conf
include /x/y.conf

port 6379
timeout 0    客户端空闲几秒后关闭连接 0禁用


daemonize yes
loglevel warning  (还有notice,verbose,debug)
logfile	/tmp/redis.log	#log文件位置,默认"",输出到控制台,如后台就不输出

databases 16  #从０开始

slave-serve-stale-data 	no 		当从不能连接主时，不允许返回过期数据，返回错误
repl-ping-slave-period 10		slave从向发ping的时间期隔10　秒
repl-timeout 60					要大于repl-ping-slave-period

##### 持久化.rdb
dbfilename	dump.rdb 	#数据快照文件名
dir	 /tmp  				#数据快照的保存目录

#save  <seconds> <changes> #保存快照到文件的频率
#after 900 sec (15 min) if at least 1 key changed
save 900 1

#after 300 sec (5 min) if at least 10 keys changed
save 300 10

stop-writes-on-bgsave-error yes   当后台save报错时,停止接收写操作
rdbcompression yes
rdbchecksum yes
可以手动执行save 命令
#####  持久化.aof  ,aof和rdb两个可以同时启用,优先用aof

appendonly no  #默认no,设置yes 会生成.aof文件,存的是明文的命令
appendfilename "appendonly.aof"
# appendfsync always
appendfsync everysec
# appendfsync no
 
auto-aof-rewrite-percentage 100   因aof文件存的命令,如果多次修改就会生成过大的文件,可以重写为一个set
auto-aof-rewrite-min-size 64mb

requirepass   <thepass>   连接要密码

连接后要用 auth <thepass> 　后才可执行命令
也可以 redis-cli -a <thepass>登录
> config get requirepass 查密码
bgrewriteaof  手工执行重写aof 文件 

如果开启aof,刚执行flushall,可以 shutdown save 防止aof文件被重写,手工修改aof文件的最后三行

redis-benchmark -n 1000   -a pass # 性能测试工具  -n <requests>
	新版本	--cluster
	
-----过期,删除的通知
基于channel的publish 和subscribe
https://redis.io/topics/notifications


 0 号数据库的键 mykey 执行 DEL key [key …] 命令时，  相当于 
PUBLISH __keyspace@0__:mykey del
PUBLISH __keyevent@0__:del mykey

--redis.conf
notify-keyspace-events xeKE

#K     Keyspace events, published with __keyspace@<db>__ prefix.
#E     Keyevent events, published with __keyevent@<db>__ prefix.
#x     Expired events (events generated every time a key expires)
#g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...

确认配置
config get notify-keyspace-events

redis-cli --csv psubscribe '__key*__:*'  
	设置为xKE测试只有expire会收到两个消息,del收不到, gxKE 才行



---- 手动 failover
配置主master
pidfile /var/run/redis.pid
port 6379
dbfilename dump.rdb
requirepass rpass
appendonly no

配置2个slave
pidfile /var/run/redis6380.pid
port 6380
dbfilename dump6380.rdb
slaveof    127.0.0.1 6379  ##slaveof 命令 在redis 5.0过时，使用 REPLICAOF
masterauth   rpass 		#在从上时设置 主的密码,主用 requirepass   <masterpass> 设置
slave-read-only yes
appendonly no

启动测试set master值,slave中看
查 info Replication

如从显示
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
slave_read_only:1
如主显示
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=6380,state=online,offset=718,lag=0
slave1:ip=127.0.0.1,port=6381,state=online,offset=718,lag=0


停master ,手动做failover

连接一个从 6380
#slaveof no one    ##slaveof 命令 在redis 5.0过时，使用 REPLICAOF
REPLICAOF NO ONE
 
config set slave-read-only  no  #也可以不配置

连接另一个从 6381
slaveof   127.0.0.1 6380   #slaveof 命令 在redis 5.0过时，使用 REPLICAOF
config set masterauth ''   ,可先用 config get master* 

----Sentinel (岗哨，哨兵) 是分布式的, 可以监控服务,如有问题可以通知外部,自动failover

redis-sentinel -v
源码目录有 sentinel.conf 可用于复制

./redis-sentinel ../sentinel.conf  必须指定配置文件(对重启使用),并且文件是可写的(自动发现slave并更新配置)
或
redis-server ../sentinel.conf --sentinel

port 26379   默认值  
pidfile "/var/run/redis-sentinel.pid"
dir "/tmp"
logfile ""
sentinel myid xxxx

sentinel monitor mymaster 127.0.0.1 6380 1
#配置格式为 sentinel <option_name> <master_name> <option_value>
#sentinel monitor <master-name> <ip> <redis-port> <quorum>  监控这个master,
sentinel monitor mymaster 127.0.0.1 6379 1  #如果有1台发现master挂了才有反应,一共3台，要设置为1
sentinel auth-pass mymaster rpass  #如使用密码,要所有的主从也使用相同的密码

sentinel down-after-milliseconds mymaster 30000   ##默认30秒,如果 ping不通或返回错误,认为master是down的
sentinel failover-timeout mymaster 180000   #如果failover操作在3分钟内未完成,认为失败

#sentinel parallel-syncs <master-name> <numslaves>  #当一个slave做failvoer到新master时,多少个salve可以和新master 做reconfig(这时不可query),可做.rdb文件传输
sentinel parallel-syncs mymaster 1

sentinel known-replica mymaster 127.0.0.1 6381
sentinel known-replica mymaster 127.0.0.1 6380

有WARNING级的日志可以做通知
sentinel notification-script mymaster /var/redis/notify.sh

连接sentinel
redis-cli  -p 26379
> sentinel masters  显示所有监控的master和状态 ,有显示ip和port 就可以直接上对数据操作
> sentinel master mymaster
> SENTINEL get-master-addr-by-name mymaster 返回mymaster的主服务器的 IP 地址和端口号
不能调用get,set

(前面有设置两个slaveof , 即6380,6381,这只做了一个 sentinel 哨兵即26379) 连redis  6379,6380,6381, 测试
 #slaveof 命令 在redis 5.0过时，使用 REPLICAOF
---




------ redis  cluster (redis-3.0 版本开始支持) 自动分片数据到多个节点上(shard,slot)
如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完整时进入fail状态
如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态
客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可


修改下面配置

port 7000			 
cluster-enabled yes
cluster-config-file nodes0.conf		#文件自动生成,不需要手工修改,配置文件中不要中文
cluster-node-timeout 5000			#毫秒 如时间内不能连接节点,认为节点失败
appendonly yes 		
appendfilename "appendonly7000.aof
pidfile /var/run/redis_7000.pid

---学习到的
slave-serve-stale-data yes  	#表示当 从与主断开 或者 复制正在进行 回复客户端,如为no则报错 
slave-priority 100   			#如果master 不能正常工作选择从的优先级
min-slaves-to-write 3          如果slave小于3个,主就不能写,最多10秒
min-slaves-max-lag 10
---
最少3个master节点,建议3个master节点 + 3个slave节点(6个配置文件)

示例建立目录 mkdir 7000 7001 7002 7003 7004 7005  每个目录中放相同的配置,并修改端口,config-file名和appendfilename名可放同一目录中,并启动
vi中批量替换 :%s/7000/70001/g

如报最大打文件数
	cat /proc/sys/fs/file-max
	vi /etc/sysctl.conf  中加  fs.file-max = 10032
	sysctl -p

redis-cli -c -p 7000 (-c cluster,-p port)
> cluster nodes 第一列以看到 node id，如是slave可以看到master是哪个
> cluster info  看 cluster_state  是 fail
> ping 

redis-5.0 开始 redis-trib.rb  已经过时 ,使用  redis-cli  代替
	./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
	./redis-trib.rb create --replicas 1 172.16.35.35:7000 172.16.35.35:7001 172.16.35.35:7002 172.16.35.35:7003 172.16.35.35:7004 172.16.35.35:7005

redis-5.0 新方法
redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001  127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1

redis-cli --cluster info 127.0.0.1:7000 
redis-cli --cluster help

----功能和上面类似
源码目录 utils/create-cluster/create-cluster 会启动3个master,3个slave，共6个 
create-cluster start 启动端口 30001 - 30006 
create-cluster create 提示输入yes

create-cluster stop 停止
-----
提示3个主节点，分3部分slot,最大值为16383 即3FFF 
	提示哪三台做M,哪三台做S,  输入yes
	其中 --replicas 1 (新的 --cluster-replicas)表示 每个主节点要一个子节点

 ./redis-cli  -p 7000  任何一台（slave也可)
	
> cluster info 显示 cluster_state:ok
			cluster_slots_ok:16384
			cluster_known_nodes:6 (不一定都是成功状态)
			cluster_size:3

> cluster nodes 可看出slave的master是谁

如果master做shutdown 那么它原来的slave变为master,自己fail
如果slove 做shutdown ,只自己fail

./redis-trib.rb reshard 127.0.0.1:7000   (shard碎片)提示输入移动slot数量（上面的有提示信息） ->提示输入接收的node id(要加数据的节点，要为master,cluster nodes 显示和上面的提示)
		->提示输入源节点（要清空的节点）->后再次提示输入源节点，也可  done 或 all
./redis-cli  --cluster reshard 127.0.0.1:7000
检查用
./redis-trib.rb check 127.0.0.1:7000
./redis-cli  --cluster check 127.0.0.1:7000
 




2的15 次方=16384 所有的slots
自己不负责的Slot的请求时，会将负责请求Key所在Slot的Redis Instance地址返回给客户端，客户端收到后自动将原请求重新发往这个地址

redis-cli -p 7000 cluster nodes | grep myself
redis-cli -p 7000 cluster nodes | grep master
redis-cli -p 7002 debug segfault 表示 让7002端口的应用掉电

./redis-trib.rb del-node 127.0.0.1:7002 <node-id>    
./redis-cli  --cluster del-node 127.0.0.1:7002  <node-id> 这个(master)节点的数据被reshard到其它节点上,其下的slave自动连接另一个master,那个master有两个slave
 这个7002的节点服务被停了
启动(带原来的配置文件)后自动加入集群
./redis-trib.rb add-node   127.0.0.1:7002 127.0.0.1:7000     第一个参数是新启动独立的,第二个是已经存在的
./redis-cli  --cluster add-node  127.0.0.1:7002 127.0.0.1:7000   
	 


查询redis允许的最大连接数  默认 4064
CONFIG GET maxclients

config get maxmemory-policy  默认为noeviction （不驱逐）,allkeys-lru,volatile-lru (对有过期时间的),allkeys-random,volatile-random,volatile-ttl,
config get maxmemory 默认为0

Redis 4.0 新的 LFU (Least Frequently Used) 
近似LRU( Least Recently Used) 清最老的数据
 volatile-lfu
 allkeys-lfu 
 
 
config set maxmemory 100000
config set maxmemory-policy  allkeys-lru


当前的redis连接数
info clients   
	看 connected_clients:xx
	 
最大占用内存
maxmemory <bytes>
info 看 used_memory

配置
slowlog-log-slower-than    微秒(microsecond，1秒 = 1,000,000 微秒)
slowlog-max-len				它决定 slow log 最多能保存多少条日志

SLOWLOG GET 命令 有执行命令，执行时间，耗时
SLOWLOG LEN
SLOWLOG RESET 清空

--------禁用  FLUSH* KEYS 配置文件增加
rename-command FLUSHALL ""  
rename-command FLUSHDB ""  
rename-command KEYS ""
rename-command SMEMBERS ""
生产环境不建议用 KEYS ，SMEMBERS 会锁很长多秒时间，使用SCAN 做替代，SSCAN(set),HSCAN(hash),ZSCAN(sorted set)
scan 0 表示从0开始 返回一个元素为一次使用的游标号，相当于分页查所有键，默认每页10页
scan 0 MATCH * COUNT 20 可通配符，设置分页大小


--------client 命令
CLIENT LIST
CLIENT GETNAME 
CLIENT SETNAME  my


--------geo开头命令
类似MySQL 的 point和geometry数据类型

geospatial

longitude 经度
latitude 纬度



--------redis-4.0新功能
UNLINK key 用法和 del 完全一样 ，但内存释放动作放到后台线程中异步执行，立即返回。
FLUSHALL [ASYNC]
FLUSHDB [ASYNC] 
rename oldkey newkey  
	如果 newkey 已经存在，redis 会先删除已经存在的 newkey，这也会引发上面提到的删除大 key 问题 ,使用lazyfree 如下配置：
	lazyfree-lazy-server-del yes/no
	
	lazyfree-lazy-eviction yes/no
	lazyfree-lazy-expire yes/no

swapdb
zlexcount
memory 
	memory usage
	memory stats
	memory doctor


malloc stats & malloc purge
这两个命令用于操作 jemalloc，只在使用 jemalloc 的时候才有效。

object freq user_key  取某个 key 的访问频度
./redis-cli --hotkeys

-----HyperLogLogs
现记录网站每天访问的独立IP数量这样的一个功能 ，要大量的数据
为了更好地解决像独立 IP 地址计算这种问题,加了 HyperLogLog 结构

只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数
只会根据输入元素来计算基数，而不会储存输入元素本身


pfadd hll a b c d  向key为hll中增加元素
pfcount hll 返回基数估算值 ，不知道元素内容


 
PFADD str1 "apple" "banana" "cherry" 
PFCOUNT str1   ###3
PFADD str2 "apple" "cherry" "durian" "mongo" 
PFCOUNT str2  ###4
PFMERGE str1and2 str1 str2 
PFCOUNT str1and2   ##5 去重的



--------redis-5.0 新的数据类型stream 
日志文件
 
#格式为 xadd key ID field string [field string ...]
XADD mystream * sensor-id 1234 temperature 19.8  ###  使用 * 为值则表示让 Redis 自行为该元素设置 ID ，命令返回的 就是新添加元素的 ID
如反回 "1573309956334-0"
# - 之前的数字为添加元素时的毫秒精度的时间戳， 而-之后的数字则是一个从 0 开始自增的数字,用于区别同一毫秒内出现的多个不同元素

XRANGE mystream 1573309711047-0 +
 # - 或者 + 来表示负无穷和正无穷



XLEN mystream 有多少个时间记录

XADD somestream 0-1 field value 返回 "0-1" 多次执行ID只可递增


历史数据
XRANGE mystream - + COUNT 2  #只要前2个时间记录，即最老的2个时间段数据
XREVRANGE mystream + - COUNT 2  #是反向的 ，即要最新的2个时间段数据



PUB/SUB的消息模型 本身并不保存任何历史消息， 某个用户的网络连接出现异常，重新加入后，他是看不到断链期间的聊天记录的
	新加入的用户同样也看不到最近一段时间的历史记录，这个对用户迅速的理解当前讨论的问题非常不便
	此外，如果Redis发生了重启，所有的用户也需要重新订阅频道。


read可以有多个消息者
所有的消息都被无限期地附加到Stream中（除非用户明确地要求删除这些条目）：不同的消费者通过记住收到的最后一条消息的ID


XREAD COUNT 2 STREAMS mystream 0   #最后参数表示最小ID


XREAD BLOCK 5000 STREAMS mystream $ #如使用BLOCK必须使用特殊的ID $ 
读最新的
在一个时间最长为 5000 毫秒的阻塞操作中， 等待 mystream 流最新添加的一个元素
如在指定时间内都没有出现新添加的元素， 那么 XREAD 命令将返回一个空值； 否则， XREAD 命令将返回流新添加的元素


概念上类似于Kafka的Consumer Group功能
XGROUP CREATE mystream mygroup $    # mystream是已经存在的stream

XADD mystream * message apple
XADD mystream * message orange
XADD mystream * message banana

XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >  #Alice是consumer名，要是组中唯一的名字 , 特殊的ID > 其意思是：消息到目前为止从未传递给其他消费者

XREADGROUP GROUP mygroup Alice STREAMS mystream 0  可以收到自己未确认的

XACK mystream mygroup 1526569495631-0  #是上面返回的ID 确认消息，再使用上面的命令就查不到了

XPENDING mystream mygroup  #显示消费者组中的每个消费者的待处理消息个数,调用不会改变任何消息的所有

XPENDING mystream mygroup - + 10  # 从开始ID到结束ID取10个  ，显示每个消息ID
显示格式
	消息ID			1573351818077-0
	消费者名称		Alice
	空闲时间（单位是毫秒）
	每一条给定的消息被传递了多少次


XRANGE mystream 1573351818077-0 1573351818077-0 查上面的消息内容，可以使用两个相同的ID做参数


XCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-2> ... <ID-N>

XCLAIM mystream mygroup Alice2 3600000 1573351818077-0  #上面的ID的这些消息可以改变他们的所有者，要求空闲时间大于指定的
.
XINFO STREAM mystream  
	显示
	first-entry第一条
	last-entry最后一条
	groups 有多少个组
	
XINFO CONSUMERS mystream mygroup  显示组中每个消息者的pending的数量，idle时间 
XINFO GROUPS mystream  #显示这个stream的group是谁，消费者数量，pending几个
XINFO HELP

XADD mystream MAXLEN 2 * value 1   ##MAXLEN 2 表示最多存2个，超出的就不存在内存中，如放在硬盘中
XADD mystream MAXLEN 2 * value 2
XADD mystream MAXLEN 2 * value 3
XLEN mystream  结果是2
 XRANGE mystream - + 发现最先进入的1没有了
 
XADD mystream MAXLEN ~ 1000 * file1 value1 # ~的意思是，我不是真的需要精确的1000个项目。它可以是1000或者1010或者1030，只要保证至少保存1000个项目就行
		当我们移除整个节点的时候才执行修整。这使得命令更高效
		

XTRIM mystream MAXLEN 10
XTRIM mystream MAXLEN ~ 10

XRANGE mystream - + COUNT 2

XDEL mystream 1573358525880-0  #删除上面返回的ID

当调用ZREM命令将有序集合中的最后一个元素删除时，这个有序集合会被彻底删除。但Stream允许在没有元素的时候仍然存在
 

--------  slaveof 命令 在redis 5.0过时，使用 REPLICAOF
 （redis-cli 下命令）
--REPLICATION 配置
 replicaof <masterip> <masterport>

 
----------------redis-6.0 新功能 
./src/redis-benchmark  有--cluster选项

--- RESP 3
RESP3 (REdis Serialization Protocol) Redis 服务端与客户端之间通信的协议
 
HELLO 3 表示客户端使用RESP3协议 
--- 客户端缓存 

--- ACL 为登录用户设置权限
https://redis.io/topics/acl

AUTH <username> <password> 变为两个参数
CONFIG GET requirepass  返回加密的SHA-256密码

ACL WHOAMI  默认显示用户名为 default
ACL LIST 显示"user default on nopass ~* +@all"   #激活的 (on),无密码 (nopass),可以仿问全部key(~*),可以仿问全部命令(+@all)

所有规则如下
	on 启用用户
	off 禁用用户
	命令 
		+<command>
		-<command>
		+@<category> ,如+@admin 有哪些使用  ACL CAT 显示所有类别命令组
	   +<command>|subcommand
		allcommands: Alias for +@all.
		nocommands: Alias for -@all
	键
		~<pattern> 是key匹配 ,如所有key就是~*
	密码	
		><password> 增加密码,一个用户可以有多个密码, 是以SHA-256存储的
		<<password> 去除密码
		#<hash> 增加密码 是SHA-256的加密的 
		!<hash> 删除这个密码,当不知道原密码,可以这样直接删
		nopass 清所有密码,可无密码登录
		resetpass 清所有密码,不能无密码登录
	reset 等同于 resetpass, resetkeys, off, -@all
	
ACL SETUSER alice  如不存在,就建立用户,后可选加很多规则,从左到右的顺序来读
ACL LIST 显示 "user alice off -@all"
ACL SETUSER alice on >p1pp0 ~cached:* +get  #可以访问cached:开头的键
AUTH alice p1pp0
测试权限

退出重进
ACL GETUSER alice
ACL SETUSER alice ~objects:* ~items:* ~public:*  #如用户存在,是在原因的权限基础上附加,即~cached:*还存在


ACL CAT dangerous 会列出这个类别里面有什么命令
ACL SETUSER myuser -client +client|setname +client|getname


ACL SETUSER virginia on allkeys +set  #建立用户 virginia 可以读全部键(allkeys 规则),可以调用set命令(+set规则)
ACL SETUSER virginia +get  #用户可以Get命令

---redis.conf 配置文件中
user <username> ... acl rules ...
aclfile /etc/redis/users.acl
----
ACL LOAD
ACL SAVE


--------TLS
https://redis.io/topics/encryption

编译时指定 make BUILD_TLS=yes 需要openssl

./utils/gen-test-certs.sh  生成根CA和服务器证书

./src/redis-server --tls-port 6379 --port 0 \
    --tls-cert-file ./tests/tls/redis.crt \
    --tls-key-file ./tests/tls/redis.key \
    --tls-ca-cert-file ./tests/tls/ca.crt


./src/redis-cli --tls \
    --cert ./tests/tls/redis.crt \
    --key ./tests/tls/redis.key \
    --cacert ./tests/tls/ca.crt
    
    
cluster 环境中使用 tls-cluster yes

Sentinel 环境中 会使用tls-replication 指令

Replication 环境中,master服务端 tls-port 和 tls-auth-clients  指令 ,replica服务端指定 tls-replication yes
    
--------



  